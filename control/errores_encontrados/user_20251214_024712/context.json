[
  {
    "timestamp": "2025-12-14T02:47:13.614734",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "tableanalyzer_init",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:13.614693",
      "operation_name": "tableanalyzer_init",
      "stdout_content": "ğŸ¯ INICIALIZANDO ANALIZADOR COMPATIBLE CON PALABRAS ANCLA\n======================================================================\nğŸ“ CARGANDO DICCIONARIOS CON PALABRAS ANCLA\nğŸ“‚ Ruta: /Users/apple/Desktop/UVM/parcial_8/BB/soluciones_prog_mov/A8_AMI/proyecto_CABI/cabi_0.0.5/diccionarios/complejos\n============================================================\nâœ… Estructura JSON de palabras ancla verificada\n   âœ… anchors/dimension_anchors.json\n   ğŸ”¥ Expandido: 19 anclas â†’ 532 dimensiones\n   âœ… anchors/metric_anchors.json\n   ğŸ”¥ Expandido: 20 anclas â†’ 490 mÃ©tricas\n   âœ… core/operations.json\n   âœ… core/known_columns.json\n   âœ… core/common_values.json\n   âš ï¸ No encontrado: linguistic/connectors.json\n   âš ï¸ No encontrado: linguistic/word_numbers.json\n   âš ï¸ No encontrado: linguistic/typo_corrections.json\n   âœ… temporal/temporal_indicators.json\n   âœ… temporal/temporal_units.json\n\nğŸ“Š RESULTADO DE CARGA CON PALABRAS ANCLA:\n   âœ… Archivos bÃ¡sicos cargados: 3/3\n   ğŸ“‚ Dimensiones (expandidas): 532\n   ğŸ“Š MÃ©tricas (expandidas): 490\n   âš¡ Operaciones: 57\n   ğŸ“ Anclas de dimensiÃ³n: 19\n   ğŸ“ Anclas de mÃ©trica: 20\n   ğŸ• Cargado: 2025-12-14 02:47:12\nâœ… Diccionarios con palabras ancla cargados exitosamente\nğŸ”¥ TODAS LAS VARIACIONES DISPONIBLES: 1022 tÃ©rminos\nâœ… Estructura JSON de palabras ancla verificada\nâœ… Diccionarios con palabras ancla cargados:\nğŸ“ Ruta: /Users/apple/Desktop/UVM/parcial_8/BB/soluciones_prog_mov/A8_AMI/proyecto_CABI/cabi_0.0.5/diccionarios/complejos\nğŸ• Ãšltima carga: 2025-12-14T02:47:12.937512\nâœ… Carga exitosa: True\nğŸ”¥ Sistema de anclas: True\nğŸ“Š EstadÃ­sticas cargadas:\n   ğŸ“‚ Dimensiones (expandidas): 532\n   ğŸ“Š MÃ©tricas (expandidas): 490\n   âš¡ Operaciones: 57\n   ğŸ“ Anclas de dimensiÃ³n: 19\n   ğŸ“ Anclas de mÃ©trica: 20\n\nğŸ”¥ EJEMPLO DE EXPANSIONES CARGADAS:\n   ğŸ“‚ 'employee': 48 variaciones â†’ ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal']...\n   ğŸ“‚ 'category': 34 variaciones â†’ ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat']...\nğŸ“ Directorios temporales verificados\nğŸ”¥ Analizador compatible con palabras ancla listo\nâœ… MySQL disponible: localhost/datos_imperiales\nğŸ”¥ Analizador con opciÃ³n MySQL listo\nâœ… ClickHouse disponible: amj0c9lgbe.us-west-2.aws.clickhouse.cloud/datos_imperiales\nğŸ”¥ Analizador con opciones MySQL + ClickHouse listo",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T02:47:13.632560",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_init",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:13.632546",
      "operation_name": "problemizador_init",
      "stdout_content": "âœ… Operaciones cargadas: 161 palabras ancla\n   ğŸ‡ªğŸ‡¸ Aliases configurados para ESPAÃ‘OL\n   âœ… Conectores activos: 30 palabras\n   âœ… NÃºmeros activos: 31 palabras\n   âœ… Correcciones activas: 20 palabras\nâœ… Diccionario temporal cargado: 387 entradas\nâœ… Diccionarios JSON cargados exitosamente\nğŸ”§ Construyendo Ã­ndices de bÃºsqueda optimizada...\nâœ… Ãndice temporal: 387 entradas\nâœ… Frases compuestas en cache: 211 entradas\nâœ… Ãndices construidos: 1011 palabras en 0.001s\nğŸ“‹ Log de palabras desconocidas cargado: 3 consultas previas\nğŸš€ Parser NLP Unificado iniciado\nğŸ“š Diccionarios cargados: {'total_dimensiones': 392, 'total_operaciones': 161, 'total_metricas': 384, 'source': 'JSON files'}\nğŸš¨ Sistema de palabras desconocidas activado\nğŸ“ Log de palabras desconocidas: control/consultas_sin_respuestas/unknown_words_log.json",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T02:47:13.634398",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "sql_mapper_init",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:13.634375",
      "operation_name": "sql_mapper_init",
      "stdout_content": "âœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T02:47:15.012052",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:15.012023",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'total sales'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'total sales'\nğŸ” DEBUG: Query con placeholders: 'total sales'\nğŸ” DEBUG: Text en minÃºsculas: 'total sales'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'total sales'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'total sales'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'total sales'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'total sales'\nğŸ” TOKENS ORIGINALES: ['total', 'sales']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['total', 'sales']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'total' (+10)\n   ğŸ‡ºğŸ‡¸ Palabra claramente inglesa: 'sales' (+15)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 25 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'total sales'\nğŸ”§ Normalizing English query: 'total sales'\nâœ… English normalized: 'total sales'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['total', 'sales']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['total', 'sales']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'sales' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['total', 'sales']\n   ğŸ“ Total tokens: 2\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['total', 'sales'] (positions 0-1)\n         ğŸ” Testing variant: 'total sales'\n         ğŸ” Testing variant: 'TOTAL SALES'\n         ğŸ” Testing variant: 'totalsales'\n         ğŸ” Testing variant: 'total(sales'\n         ğŸ” Testing variant: 'TOTALSALES'\n         ğŸ” Testing variant: 'total_sales'\n         ğŸ” Testing variant: 'TOTAL_SALES'\n         ğŸ” Testing variant: 'Total Sales'\n      ğŸ” Testing combination: ['total'] (positions 0-0)\n         ğŸ” Testing variant: 'total'\n         ğŸ” Testing variant: 'TOTAL'\n         ğŸ” Testing variant: 'Total'\n      ğŸ” Testing combination: ['sales'] (positions 1-1)\n         ğŸ” Testing variant: 'sales'\n         ğŸ” Testing variant: 'SALES'\n         ğŸ” Testing variant: 'Sales'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'total' classified as operation\nğŸ” English token 'sales' classified as metric\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   ğŸ“Š Segments detected: [['total', 'sales']]\n\n   ğŸ¯ Processing English segment 1: ['total', 'sales']\n      ğŸ” Analyzing English segment: ['total', 'sales']\n         âš¡ English operation found: total\n         ğŸ“Š English REAL metric found: sales\n         âœ… English criteria complete: total + sales\n      âœ… English criteria extracted: total sales\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 1\n   1. total sales (confidence: 0.95)\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 1\n   ğŸ¯ Is compound: False\n   âš¡ English operation: total\n   ğŸ“Š English metric: sales\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['total']\n   ğŸ“Š Metrics: ['sales']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (global)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'total sales'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   âœ… English global aggregation valid - no main dimension required\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸŒ Generating English SQL for global aggregation\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT SUM(sales) FROM datos;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT SUM(sales) FROM datos;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT SUM(sales) FROM datos;\n   ğŸ” Function found: SUM(sales)\n      ğŸ” Searching for 'sales' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sales' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sales) â†’ SUM(Sell_Out)\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT SUM(Sell_Out) FROM datos;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 11\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT SUM(\"Sell_Out\") FROM datos;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 1\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… OperaciÃ³n+MÃ©trica tradicional: ((total) (sales))\n   ğŸ¯ Resultado final COMPUESTO: ((total) (sales))\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT SUM(\"Sell_Out\") FROM datos;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T02:47:23.072750",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:23.072688",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'total sales'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'total sales'\nğŸ” DEBUG: Query con placeholders: 'total sales'\nğŸ” DEBUG: Text en minÃºsculas: 'total sales'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'total sales'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'total sales'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'total sales'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'total sales'\nğŸ” TOKENS ORIGINALES: ['total', 'sales']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['total', 'sales']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'total' (+10)\n   ğŸ‡ºğŸ‡¸ Palabra claramente inglesa: 'sales' (+15)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 25 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'total sales'\nğŸ”§ Normalizing English query: 'total sales'\nâœ… English normalized: 'total sales'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['total', 'sales']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['total', 'sales']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'sales' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['total', 'sales']\n   ğŸ“ Total tokens: 2\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['total', 'sales'] (positions 0-1)\n         ğŸ” Testing variant: 'total sales'\n         ğŸ” Testing variant: 'TOTAL SALES'\n         ğŸ” Testing variant: 'totalsales'\n         ğŸ” Testing variant: 'total(sales'\n         ğŸ” Testing variant: 'TOTALSALES'\n         ğŸ” Testing variant: 'total_sales'\n         ğŸ” Testing variant: 'TOTAL_SALES'\n         ğŸ” Testing variant: 'Total Sales'\n      ğŸ” Testing combination: ['total'] (positions 0-0)\n         ğŸ” Testing variant: 'total'\n         ğŸ” Testing variant: 'TOTAL'\n         ğŸ” Testing variant: 'Total'\n      ğŸ” Testing combination: ['sales'] (positions 1-1)\n         ğŸ” Testing variant: 'sales'\n         ğŸ” Testing variant: 'SALES'\n         ğŸ” Testing variant: 'Sales'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'total' classified as operation\nğŸ” English token 'sales' classified as metric\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   ğŸ“Š Segments detected: [['total', 'sales']]\n\n   ğŸ¯ Processing English segment 1: ['total', 'sales']\n      ğŸ” Analyzing English segment: ['total', 'sales']\n         âš¡ English operation found: total\n         ğŸ“Š English REAL metric found: sales\n         âœ… English criteria complete: total + sales\n      âœ… English criteria extracted: total sales\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 1\n   1. total sales (confidence: 0.95)\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 1\n   ğŸ¯ Is compound: False\n   âš¡ English operation: total\n   ğŸ“Š English metric: sales\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['total']\n   ğŸ“Š Metrics: ['sales']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (global)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'total sales'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   âœ… English global aggregation valid - no main dimension required\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸŒ Generating English SQL for global aggregation\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT SUM(sales) FROM datos;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT SUM(sales) FROM datos;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT SUM(sales) FROM datos;\n   ğŸ” Function found: SUM(sales)\n      ğŸ” Searching for 'sales' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sales' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sales) â†’ SUM(Sell_Out)\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT SUM(Sell_Out) FROM datos;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 11\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT SUM(\"Sell_Out\") FROM datos;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 1\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… OperaciÃ³n+MÃ©trica tradicional: ((total) (sales))\n   ğŸ¯ Resultado final COMPUESTO: ((total) (sales))\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT SUM(\"Sell_Out\") FROM datos;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T02:47:36.986027",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T02:47:36.985985",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list fist 2 rows'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list fist 2 rows'\nğŸ” DEBUG: Query con placeholders: 'list fist 2 rows'\nğŸ” DEBUG: Text en minÃºsculas: 'list fist 2 rows'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list fist 2 rows'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list fist 2 rows'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list fist 2 rows'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list fist 2 rows'\nğŸ” TOKENS ORIGINALES: ['list', 'fist', '2', 'rows']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'fist', '2', 'rows']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'rows' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list fist 2 rows'\nğŸ”§ Normalizing English query: 'list fist 2 rows'\nâœ… English normalized: 'list fist 2 rows'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'fist', '2', 'rows']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'fist', '2', 'rows']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'rows' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'fist', '2', 'rows']\n   ğŸ“ Total tokens: 4\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'fist', '2', 'rows']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'fist', '2', 'rows']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'fist', '2', 'rows'] (positions 0-3)\n         ğŸ” Testing variant: 'list fist 2 rows'\n         ğŸ” Testing variant: 'LIST FIST 2 ROWS'\n         ğŸ” Testing variant: 'listfist2rows'\n         ğŸ” Testing variant: 'list(fist(2(rows'\n         ğŸ” Testing variant: 'LISTFIST2ROWS'\n         ğŸ” Testing variant: 'list_fist_2_rows'\n         ğŸ” Testing variant: 'LIST_FIST_2_ROWS'\n         ğŸ” Testing variant: 'List Fist 2 Rows'\n      ğŸ” Testing combination: ['list', 'fist', '2'] (positions 0-2)\n         ğŸ” Testing variant: 'list fist 2'\n         ğŸ” Testing variant: 'LIST FIST 2'\n         ğŸ” Testing variant: 'listfist2'\n         ğŸ” Testing variant: 'list(fist(2'\n         ğŸ” Testing variant: 'LISTFIST2'\n         ğŸ” Testing variant: 'list_fist_2'\n         ğŸ” Testing variant: 'LIST_FIST_2'\n         ğŸ” Testing variant: 'List Fist 2'\n      ğŸ” Testing combination: ['list', 'fist'] (positions 0-1)\n         ğŸ” Testing variant: 'list fist'\n         ğŸ” Testing variant: 'LIST FIST'\n         ğŸ” Testing variant: 'listfist'\n         ğŸ” Testing variant: 'list(fist'\n         ğŸ” Testing variant: 'LISTFIST'\n         ğŸ” Testing variant: 'list_fist'\n         ğŸ” Testing variant: 'LIST_FIST'\n         ğŸ” Testing variant: 'List Fist'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['fist', '2', 'rows'] (positions 1-3)\n         ğŸ” Testing variant: 'fist 2 rows'\n         ğŸ” Testing variant: 'FIST 2 ROWS'\n         ğŸ” Testing variant: 'fist2rows'\n         ğŸ” Testing variant: 'fist(2(rows'\n         ğŸ” Testing variant: 'FIST2ROWS'\n         ğŸ” Testing variant: 'fist_2_rows'\n         ğŸ” Testing variant: 'FIST_2_ROWS'\n         ğŸ” Testing variant: 'Fist 2 Rows'\n      ğŸ” Testing combination: ['fist', '2'] (positions 1-2)\n         ğŸ” Testing variant: 'fist 2'\n         ğŸ” Testing variant: 'FIST 2'\n         ğŸ” Testing variant: 'fist2'\n         ğŸ” Testing variant: 'fist(2'\n         ğŸ” Testing variant: 'FIST2'\n         ğŸ” Testing variant: 'fist_2'\n         ğŸ” Testing variant: 'FIST_2'\n         ğŸ” Testing variant: 'Fist 2'\n      ğŸ” Testing combination: ['fist'] (positions 1-1)\n         ğŸ” Testing variant: 'fist'\n         ğŸ” Testing variant: 'FIST'\n         ğŸ” Testing variant: 'Fist'\n      ğŸ” Testing combination: ['2', 'rows'] (positions 2-3)\n         ğŸ” Testing variant: '2 rows'\n         ğŸ” Testing variant: '2 ROWS'\n         ğŸ” Testing variant: '2rows'\n         ğŸ” Testing variant: '2(rows'\n         ğŸ” Testing variant: '2ROWS'\n         ğŸ” Testing variant: '2_rows'\n         ğŸ” Testing variant: '2_ROWS'\n         ğŸ” Testing variant: '2 Rows'\n      ğŸ” Testing combination: ['2'] (positions 2-2)\n         ğŸ” Testing variant: '2'\n      ğŸ” Testing combination: ['rows'] (positions 3-3)\n         ğŸ” Testing variant: 'rows'\n         ğŸ” Testing variant: 'ROWS'\n         ğŸ” Testing variant: 'Rows'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'fist', '2', 'rows']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'fist', '2', 'rows']\n   âœ… List indicator: 'list' at position 0\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'fist', '2', 'rows']\n   âœ… Show indicator: 'list' at position 0\n   âœ… Row count (number): 2\n   âœ… Object type: 'rows'\nğŸ“Š SHOW ROWS PATTERN DETECTED:\n   ğŸ“Š Show indicator: list\n   ğŸ“ Position: None\n   ğŸ”¢ Row count: 2\n   ğŸ“‹ Object type: rows\n   â­ Confidence: 1.00\nğŸ“Š DEBUG: show_rows_pattern = True\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'fist' classified as unknown\nğŸ” English token '2' classified as value\nğŸ” English token 'rows' classified as connector\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'fist', '2', 'rows']\n   âœ… Show indicator: 'list' at position 0\n   âœ… Row count (number): 2\n   âœ… Object type: 'rows'\nğŸ“Š SHOW ROWS PATTERN DETECTED:\n   ğŸ“Š Show indicator: list\n   ğŸ“ Position: None\n   ğŸ”¢ Row count: 2\n   ğŸ“‹ Object type: rows\n   â­ Confidence: 1.00\n   ğŸ“Š Show rows pattern detected: True\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'fist', '2', 'rows']\n   âœ… List indicator: 'list' at position 0\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'fist', '2', 'rows']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'fist', '2', 'rows']\n   ğŸ“Š Segments detected: [['list', 'fist', '2', 'rows']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'fist', '2', 'rows']\n      ğŸ” Analyzing English segment: ['list', 'fist', '2', 'rows']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“Š Structure marked as SHOW_ROWS (overriding ranking)\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: SHOW_ROWS (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list fist 2 rows'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: show_rows\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: True\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ“Š SHOW_ROWS pattern detected - using special validation\n   âœ… SHOW_ROWS validation passed - count: 2\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“Š DETECTED: English show rows â†’ using specialized generator\nğŸ“Š GENERATING SHOW ROWS SQL:\n   ğŸ“Š Show type: list\n   ğŸ“ Position: None\n   ğŸ”¢ Count: 2\n   ğŸ“‹ Object: rows\n   ğŸ”„ Using ascending order for 'default' rows\n   ğŸ¯ Show rows SQL: SELECT * FROM datos ORDER BY id ASC LIMIT 2;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT * FROM datos ORDER BY id ASC LIMIT 2;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT * FROM datos ORDER BY id ASC LIMIT 2;\n      ğŸ” Searching for 'id' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sell_through' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sales_amount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'order_number' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'profit' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'margin' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'quantity' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Inventory' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'price' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'cost' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'orders' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'transactions' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_8w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_4w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Week' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'roi' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'discount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'revenue' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Venta_perdida' (data type: <class 'list'>)\n      âŒ No mapping found for 'id'\n      ğŸ” DEBUG - Sample dimension_anchors structure:\n         'employee': <class 'list'> = ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal', 'staff', 'agente', 'agentes', 'representante', 'representantes', 'ejecutivo', 'ejecutivos', 'asesor', 'asesores', 'colaborador', 'colaboradores', 'trabajador', 'trabajadores', 'operador', 'operadores', 'consultor', 'consultores', 'employee', 'employees', 'worker', 'workers', 'staff', 'personnel', 'agent', 'agents', 'representative', 'representatives', 'executive', 'executives', 'advisor', 'advisors', 'consultant', 'consultants', 'operator', 'operators', 'associate', 'associates', 'team_member', 'team_members', 'crew', 'workforce', 'human_resource', 'human_resources']\n         'category': <class 'list'> = ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat', 'cats', 'clasificacion', 'clasificaciones', 'clasificaciÃ³n', 'segmento', 'segmentos', 'division', 'divisiones', 'divisiÃ³n', 'category', 'categories', 'classification', 'classifications', 'segment', 'segments', 'division', 'divisions', 'group', 'groups', 'type', 'types', 'kind', 'kinds', 'class', 'classes', 'section', 'sections', 'grouping', 'groupings']\n         'brand': <class 'list'> = ['marca', 'marcas', 'brand', 'brands', 'etiqueta', 'etiquetas', 'label', 'labels', 'fabricante', 'fabricantes', 'proveedor_marca', 'casa', 'casas', 'firma', 'firmas', 'nombre_comercial', 'manufacturer', 'manufacturers', 'maker', 'makers', 'producer', 'producers', 'supplier', 'suppliers', 'vendor', 'vendors', 'company', 'companies', 'trademark', 'trademarks', 'brandname', 'brandnames', 'marque', 'logo']\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT * FROM datos ORDER BY id ASC LIMIT 2;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n   ğŸ“¤ Output: SELECT * FROM datos ORDER BY id ASC LIMIT 2;\n   ğŸ“Š Reemplazos realizados: 0\n   ğŸ“¤ Output: SELECT * FROM datos ORDER BY id ASC LIMIT 2;\n   ğŸ“Š Reemplazos realizados: 0\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT * FROM datos ORDER BY id ASC LIMIT 2;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT * FROM datos ORDER BY id ASC LIMIT 2;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:22:25.203336",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:22:25.203057",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'total sales'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'total sales'\nğŸ” DEBUG: Query con placeholders: 'total sales'\nğŸ” DEBUG: Text en minÃºsculas: 'total sales'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'total sales'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'total sales'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'total sales'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'total sales'\nğŸ” TOKENS ORIGINALES: ['total', 'sales']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['total', 'sales']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'total' (+10)\n   ğŸ‡ºğŸ‡¸ Palabra claramente inglesa: 'sales' (+15)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 25 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'total sales'\nğŸ”§ Normalizing English query: 'total sales'\nâœ… English normalized: 'total sales'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['total', 'sales']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['total', 'sales']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'sales' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['total', 'sales']\n   ğŸ“ Total tokens: 2\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['total', 'sales'] (positions 0-1)\n         ğŸ” Testing variant: 'total sales'\n         ğŸ” Testing variant: 'TOTAL SALES'\n         ğŸ” Testing variant: 'totalsales'\n         ğŸ” Testing variant: 'total(sales'\n         ğŸ” Testing variant: 'TOTALSALES'\n         ğŸ” Testing variant: 'total_sales'\n         ğŸ” Testing variant: 'TOTAL_SALES'\n         ğŸ” Testing variant: 'Total Sales'\n      ğŸ” Testing combination: ['total'] (positions 0-0)\n         ğŸ” Testing variant: 'total'\n         ğŸ” Testing variant: 'TOTAL'\n         ğŸ” Testing variant: 'Total'\n      ğŸ” Testing combination: ['sales'] (positions 1-1)\n         ğŸ” Testing variant: 'sales'\n         ğŸ” Testing variant: 'SALES'\n         ğŸ” Testing variant: 'Sales'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'total' classified as operation\nğŸ” English token 'sales' classified as metric\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   ğŸ“Š Segments detected: [['total', 'sales']]\n\n   ğŸ¯ Processing English segment 1: ['total', 'sales']\n      ğŸ” Analyzing English segment: ['total', 'sales']\n         âš¡ English operation found: total\n         ğŸ“Š English REAL metric found: sales\n         âœ… English criteria complete: total + sales\n      âœ… English criteria extracted: total sales\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 1\n   1. total sales (confidence: 0.95)\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 1\n   ğŸ¯ Is compound: False\n   âš¡ English operation: total\n   ğŸ“Š English metric: sales\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['total']\n   ğŸ“Š Metrics: ['sales']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (global)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'total sales'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   âœ… English global aggregation valid - no main dimension required\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸŒ Generating English SQL for global aggregation\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT SUM(sales) FROM datos;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT SUM(sales) FROM datos;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT SUM(sales) FROM datos;\n   ğŸ” Function found: SUM(sales)\n      ğŸ” Searching for 'sales' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sales' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sales) â†’ SUM(Sell_Out)\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT SUM(Sell_Out) FROM datos;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 11\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT SUM(\"Sell_Out\") FROM datos;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 1\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… OperaciÃ³n+MÃ©trica tradicional: ((total) (sales))\n   ğŸ¯ Resultado final COMPUESTO: ((total) (sales))\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT SUM(\"Sell_Out\") FROM datos;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:41:53.692336",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:41:53.692277",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'total sales'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'total sales'\nğŸ” DEBUG: Query con placeholders: 'total sales'\nğŸ” DEBUG: Text en minÃºsculas: 'total sales'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'total sales'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'total sales'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'total sales'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'total sales'\nğŸ” TOKENS ORIGINALES: ['total', 'sales']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['total', 'sales']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'total' (+10)\n   ğŸ‡ºğŸ‡¸ Palabra claramente inglesa: 'sales' (+15)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 25 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'total sales'\nğŸ”§ Normalizing English query: 'total sales'\nâœ… English normalized: 'total sales'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['total', 'sales']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['total', 'sales']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'sales' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['total', 'sales']\n   ğŸ“ Total tokens: 2\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['total', 'sales'] (positions 0-1)\n         ğŸ” Testing variant: 'total sales'\n         ğŸ” Testing variant: 'TOTAL SALES'\n         ğŸ” Testing variant: 'totalsales'\n         ğŸ” Testing variant: 'total(sales'\n         ğŸ” Testing variant: 'TOTALSALES'\n         ğŸ” Testing variant: 'total_sales'\n         ğŸ” Testing variant: 'TOTAL_SALES'\n         ğŸ” Testing variant: 'Total Sales'\n      ğŸ” Testing combination: ['total'] (positions 0-0)\n         ğŸ” Testing variant: 'total'\n         ğŸ” Testing variant: 'TOTAL'\n         ğŸ” Testing variant: 'Total'\n      ğŸ” Testing combination: ['sales'] (positions 1-1)\n         ğŸ” Testing variant: 'sales'\n         ğŸ” Testing variant: 'SALES'\n         ğŸ” Testing variant: 'Sales'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'total' classified as operation\nğŸ” English token 'sales' classified as metric\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales']\n   ğŸ“Š Segments detected: [['total', 'sales']]\n\n   ğŸ¯ Processing English segment 1: ['total', 'sales']\n      ğŸ” Analyzing English segment: ['total', 'sales']\n         âš¡ English operation found: total\n         ğŸ“Š English REAL metric found: sales\n         âœ… English criteria complete: total + sales\n      âœ… English criteria extracted: total sales\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 1\n   1. total sales (confidence: 0.95)\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 1\n   ğŸ¯ Is compound: False\n   âš¡ English operation: total\n   ğŸ“Š English metric: sales\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['total']\n   ğŸ“Š Metrics: ['sales']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (global)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'total sales'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   âœ… English global aggregation valid - no main dimension required\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸŒ Generating English SQL for global aggregation\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT SUM(sales) FROM datos;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT SUM(sales) FROM datos;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT SUM(sales) FROM datos;\n   ğŸ” Function found: SUM(sales)\n      ğŸ” Searching for 'sales' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sales' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sales) â†’ SUM(Sell_Out)\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT SUM(Sell_Out) FROM datos;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 11\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos;\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT SUM(\"Sell_Out\") FROM datos;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 1\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… OperaciÃ³n+MÃ©trica tradicional: ((total) (sales))\n   ğŸ¯ Resultado final COMPUESTO: ((total) (sales))\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT SUM(\"Sell_Out\") FROM datos;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:43:47.101962",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:43:47.101892",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'total sales of heb'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'total sales of heb'\nğŸ” DEBUG: Query con placeholders: 'total sales of heb'\nğŸ” DEBUG: Text en minÃºsculas: 'total sales of heb'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'total sales of heb'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'total sales of heb'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'total sales of heb'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'total sales of heb'\nğŸ” TOKENS ORIGINALES: ['total', 'sales', 'of', 'heb']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['total', 'sales', 'of', 'heb']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'total' (+10)\n   ğŸ‡ºğŸ‡¸ Palabra claramente inglesa: 'sales' (+15)\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'of' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 35 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'total sales of heb'\nğŸ”§ Normalizing English query: 'total sales of heb'\nâœ… English normalized: 'total sales of heb'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['total', 'sales', 'of', 'heb']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['total', 'sales', 'of', 'heb']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'sales' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['total', 'sales', 'of', 'heb']\n   ğŸ“ Total tokens: 4\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['total', 'sales', 'of', 'heb'] (positions 0-3)\n         ğŸ” Testing variant: 'total sales of heb'\n         ğŸ” Testing variant: 'TOTAL SALES OF HEB'\n         ğŸ” Testing variant: 'totalsalesofheb'\n         ğŸ” Testing variant: 'total(sales(of(heb'\n         ğŸ” Testing variant: 'TOTALSALESOFHEB'\n         ğŸ” Testing variant: 'total_sales_of_heb'\n         ğŸ” Testing variant: 'TOTAL_SALES_OF_HEB'\n         ğŸ” Testing variant: 'Total Sales Of Heb'\n      ğŸ” Testing combination: ['total', 'sales', 'of'] (positions 0-2)\n         ğŸ” Testing variant: 'total sales of'\n         ğŸ” Testing variant: 'TOTAL SALES OF'\n         ğŸ” Testing variant: 'totalsalesof'\n         ğŸ” Testing variant: 'total(sales(of'\n         ğŸ” Testing variant: 'TOTALSALESOF'\n         ğŸ” Testing variant: 'total_sales_of'\n         ğŸ” Testing variant: 'TOTAL_SALES_OF'\n         ğŸ” Testing variant: 'Total Sales Of'\n      ğŸ” Testing combination: ['total', 'sales'] (positions 0-1)\n         ğŸ” Testing variant: 'total sales'\n         ğŸ” Testing variant: 'TOTAL SALES'\n         ğŸ” Testing variant: 'totalsales'\n         ğŸ” Testing variant: 'total(sales'\n         ğŸ” Testing variant: 'TOTALSALES'\n         ğŸ” Testing variant: 'total_sales'\n         ğŸ” Testing variant: 'TOTAL_SALES'\n         ğŸ” Testing variant: 'Total Sales'\n      ğŸ” Testing combination: ['total'] (positions 0-0)\n         ğŸ” Testing variant: 'total'\n         ğŸ” Testing variant: 'TOTAL'\n         ğŸ” Testing variant: 'Total'\n      ğŸ” Testing combination: ['sales', 'of', 'heb'] (positions 1-3)\n         ğŸ” Testing variant: 'sales of heb'\n         ğŸ” Testing variant: 'SALES OF HEB'\n         ğŸ” Testing variant: 'salesofheb'\n         ğŸ” Testing variant: 'sales(of(heb'\n         ğŸ” Testing variant: 'SALESOFHEB'\n         ğŸ” Testing variant: 'sales_of_heb'\n         ğŸ” Testing variant: 'SALES_OF_HEB'\n         ğŸ” Testing variant: 'Sales Of Heb'\n      ğŸ” Testing combination: ['sales', 'of'] (positions 1-2)\n         ğŸ” Testing variant: 'sales of'\n         ğŸ” Testing variant: 'SALES OF'\n         ğŸ” Testing variant: 'salesof'\n         ğŸ” Testing variant: 'sales(of'\n         ğŸ” Testing variant: 'SALESOF'\n         ğŸ” Testing variant: 'sales_of'\n         ğŸ” Testing variant: 'SALES_OF'\n         ğŸ” Testing variant: 'Sales Of'\n      ğŸ” Testing combination: ['sales'] (positions 1-1)\n         ğŸ” Testing variant: 'sales'\n         ğŸ” Testing variant: 'SALES'\n         ğŸ” Testing variant: 'Sales'\n      ğŸ” Testing combination: ['of', 'heb'] (positions 2-3)\n         ğŸ” Testing variant: 'of heb'\n         ğŸ” Testing variant: 'OF HEB'\n         ğŸ” Testing variant: 'ofheb'\n         ğŸ” Testing variant: 'of(heb'\n         ğŸ” Testing variant: 'OFHEB'\n         ğŸ” Testing variant: 'of_heb'\n         ğŸ” Testing variant: 'OF_HEB'\n         ğŸ” Testing variant: 'Of Heb'\n      ğŸ” Testing combination: ['of'] (positions 2-2)\n         ğŸ” Testing variant: 'of'\n         ğŸ” Testing variant: 'OF'\n         ğŸ” Testing variant: 'Of'\n      ğŸ” Testing combination: ['heb'] (positions 3-3)\n         ğŸ” Testing variant: 'heb'\n         âœ… MATCH FOUND: 'heb' â†’ {'original_value': 'HEB', 'column_name': 'Account', 'column_type': 'dimension', 'variants': ['HEB', 'heb'], 'confidence': 1.0}\n         ğŸ§  Analyzing context for implicit value...\n            ğŸ“ Before: ['total', 'sales', 'of']\n            ğŸ“ After: []\n            ğŸ“‹ Value column: account\n            âœ… COUNT pattern detected\n            âœ… METRIC pattern detected\n      âœ… IMPLICIT VALUE DETECTED:\n         ğŸ“ Value: 'HEB'\n         ğŸ“‹ Column: Account\n         ğŸ¯ Context: COUNT_PATTERN_METRIC_PATTERN\n         â­ Confidence: 1.00\n         ğŸ”’ Positions processed: [3]\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 1\nğŸ”’ TOTAL POSITIONS PROCESSED: [3]\n   âœ… Implicit filters found: 1\n      ğŸ” account = 'HEB' (confidence: 1.00)\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: [3]\nğŸ” Testing TEMPORAL DICT pattern: 'sales' + [value from dictionary]\n      ğŸ—„ï¸ Searching temporal dictionary starting at position 2\n         ğŸ” Testing 2 tokens: ['of', 'heb']\n            ğŸ” Testing variant: 'of heb'\n            ğŸ” Testing variant: 'ofheb'\n            ğŸ” Testing variant: 'of_heb'\n            ğŸ” Testing variant: 'OF HEB'\n            ğŸ” Testing variant: 'OFHEB'\n            ğŸ” Testing variant: 'OF_HEB'\n         ğŸ” Testing 1 tokens: ['of']\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'OF'\n            ğŸ” Testing variant: 'OF'\n            ğŸ” Testing variant: 'OF'\n         âŒ No matches found in temporal dictionary\nâ­• PREPOSITION PATTERN: positions {1, 2, 3} overlap with processed {3}\nğŸ¯ Total filters detected: 1\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 1\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: [3]\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 1\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales', 'of', 'heb']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ”— English filter detected: account = 'HEB'\nğŸ” English token 'total' classified as operation\nğŸ” English token 'sales' classified as metric\nğŸ” English token 'of' classified as connector\nğŸ¯ English token 'heb' classified as value (used in filter)\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['total', 'sales', 'of', 'heb']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   ğŸ“Š Segments detected: [['total', 'sales', 'of', 'heb']]\n\n   ğŸ¯ Processing English segment 1: ['total', 'sales', 'of', 'heb']\n      ğŸ” Analyzing English segment: ['total', 'sales', 'of', 'heb']\n         âš¡ English operation found: total\n         ğŸ“Š English REAL metric found: sales\n         âœ… English criteria complete: total + sales\n      âœ… English criteria extracted: total sales\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 1\n   1. total sales (confidence: 0.95)\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 1\n   ğŸ¯ Is compound: False\n   âš¡ English operation: total\n   ğŸ“Š English metric: sales\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['total']\n   ğŸ“Š Metrics: ['sales']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (global)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['total', 'sales', 'of', 'heb']\n   âŒ No question word found\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'total sales of heb'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   âœ… English global aggregation valid - no main dimension required\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸŒ Generating English SQL for global aggregation\n   âœ… English WHERE condition: account = 'HEB'\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT SUM(sales) FROM datos WHERE account = 'HEB';\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT SUM(sales) FROM datos WHERE account = 'HEB';'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT SUM(sales) FROM datos WHERE account = 'HEB';\n   ğŸ” Function found: SUM(sales)\n      ğŸ” Searching for 'sales' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sales' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sales) â†’ SUM(Sell_Out)\n      ğŸ” Searching for 'account' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n      âœ… Dimension match: 'account' â†’ 'Account' (list structure)\n   ğŸ”„ Standalone mapping: 'account' â†’ Account\n      ğŸ” Searching for 'HEB' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sell_through' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sales_amount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'order_number' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'profit' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'margin' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'quantity' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Inventory' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'price' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'cost' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'orders' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'transactions' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_8w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_4w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Week' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'roi' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'discount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'revenue' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Venta_perdida' (data type: <class 'list'>)\n      âŒ No mapping found for 'HEB'\n      ğŸ” DEBUG - Sample dimension_anchors structure:\n         'employee': <class 'list'> = ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal', 'staff', 'agente', 'agentes', 'representante', 'representantes', 'ejecutivo', 'ejecutivos', 'asesor', 'asesores', 'colaborador', 'colaboradores', 'trabajador', 'trabajadores', 'operador', 'operadores', 'consultor', 'consultores', 'employee', 'employees', 'worker', 'workers', 'staff', 'personnel', 'agent', 'agents', 'representative', 'representatives', 'executive', 'executives', 'advisor', 'advisors', 'consultant', 'consultants', 'operator', 'operators', 'associate', 'associates', 'team_member', 'team_members', 'crew', 'workforce', 'human_resource', 'human_resources']\n         'category': <class 'list'> = ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat', 'cats', 'clasificacion', 'clasificaciones', 'clasificaciÃ³n', 'segmento', 'segmentos', 'division', 'divisiones', 'divisiÃ³n', 'category', 'categories', 'classification', 'classifications', 'segment', 'segments', 'division', 'divisions', 'group', 'groups', 'type', 'types', 'kind', 'kinds', 'class', 'classes', 'section', 'sections', 'grouping', 'groupings']\n         'brand': <class 'list'> = ['marca', 'marcas', 'brand', 'brands', 'etiqueta', 'etiquetas', 'label', 'labels', 'fabricante', 'fabricantes', 'proveedor_marca', 'casa', 'casas', 'firma', 'firmas', 'nombre_comercial', 'manufacturer', 'manufacturers', 'maker', 'makers', 'producer', 'producers', 'supplier', 'suppliers', 'vendor', 'vendors', 'company', 'companies', 'trademark', 'trademarks', 'brandname', 'brandnames', 'marque', 'logo']\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT SUM(Sell_Out) FROM datos WHERE Account = 'HEB';\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 11\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 40\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB';\n   ğŸ“Š Reemplazos realizados: 2\n   ğŸ“¤ Output: SELECT SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB';\n   ğŸ“Š Reemplazos realizados: 2\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB';'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 1\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Conservando filtro: account = HEB\n   âœ… Filtros directos (no temporales): [\"(account = 'HEB')\"]\n   âœ… OperaciÃ³n+MÃ©trica tradicional: ((total) (sales))\n   ğŸ”§ CombinaciÃ³n estÃ¡ndar (mÃºltiples condiciones): (account = 'HEB') Y ((total) (sales))\n   ğŸ¯ Resultado final COMPUESTO: (account = 'HEB') Y ((total) (sales))\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB';'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:44:08.786853",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:44:08.786826",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all stores of heb'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all stores of heb'\nğŸ” DEBUG: Query con placeholders: 'list all stores of heb'\nğŸ” DEBUG: Text en minÃºsculas: 'list all stores of heb'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all stores of heb'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all stores of heb'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all stores of heb'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all stores of heb'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'stores', 'of', 'heb']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'stores', 'of', 'heb']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'of' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 20 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all stores of heb'\nğŸ”§ Normalizing English query: 'list all stores of heb'\nâœ… English normalized: 'list all stores of heb'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'stores', 'of', 'heb']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'stores', 'of', 'heb']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'stores' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'stores', 'of', 'heb']\n   ğŸ“ Total tokens: 5\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'stores', 'of', 'heb'] (positions 0-4)\n         ğŸ” Testing variant: 'list all stores of heb'\n         ğŸ” Testing variant: 'LIST ALL STORES OF HEB'\n         ğŸ” Testing variant: 'listallstoresofheb'\n         ğŸ” Testing variant: 'list(all(stores(of(heb'\n         ğŸ” Testing variant: 'LISTALLSTORESOFHEB'\n         ğŸ” Testing variant: 'list_all_stores_of_heb'\n         ğŸ” Testing variant: 'LIST_ALL_STORES_OF_HEB'\n         ğŸ” Testing variant: 'List All Stores Of Heb'\n      ğŸ” Testing combination: ['list', 'all', 'stores', 'of'] (positions 0-3)\n         ğŸ” Testing variant: 'list all stores of'\n         ğŸ” Testing variant: 'LIST ALL STORES OF'\n         ğŸ” Testing variant: 'listallstoresof'\n         ğŸ” Testing variant: 'list(all(stores(of'\n         ğŸ” Testing variant: 'LISTALLSTORESOF'\n         ğŸ” Testing variant: 'list_all_stores_of'\n         ğŸ” Testing variant: 'LIST_ALL_STORES_OF'\n         ğŸ” Testing variant: 'List All Stores Of'\n      ğŸ” Testing combination: ['list', 'all', 'stores'] (positions 0-2)\n         ğŸ” Testing variant: 'list all stores'\n         ğŸ” Testing variant: 'LIST ALL STORES'\n         ğŸ” Testing variant: 'listallstores'\n         ğŸ” Testing variant: 'list(all(stores'\n         ğŸ” Testing variant: 'LISTALLSTORES'\n         ğŸ” Testing variant: 'list_all_stores'\n         ğŸ” Testing variant: 'LIST_ALL_STORES'\n         ğŸ” Testing variant: 'List All Stores'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'stores', 'of', 'heb'] (positions 1-4)\n         ğŸ” Testing variant: 'all stores of heb'\n         ğŸ” Testing variant: 'ALL STORES OF HEB'\n         ğŸ” Testing variant: 'allstoresofheb'\n         ğŸ” Testing variant: 'all(stores(of(heb'\n         ğŸ” Testing variant: 'ALLSTORESOFHEB'\n         ğŸ” Testing variant: 'all_stores_of_heb'\n         ğŸ” Testing variant: 'ALL_STORES_OF_HEB'\n         ğŸ” Testing variant: 'All Stores Of Heb'\n      ğŸ” Testing combination: ['all', 'stores', 'of'] (positions 1-3)\n         ğŸ” Testing variant: 'all stores of'\n         ğŸ” Testing variant: 'ALL STORES OF'\n         ğŸ” Testing variant: 'allstoresof'\n         ğŸ” Testing variant: 'all(stores(of'\n         ğŸ” Testing variant: 'ALLSTORESOF'\n         ğŸ” Testing variant: 'all_stores_of'\n         ğŸ” Testing variant: 'ALL_STORES_OF'\n         ğŸ” Testing variant: 'All Stores Of'\n      ğŸ” Testing combination: ['all', 'stores'] (positions 1-2)\n         ğŸ” Testing variant: 'all stores'\n         ğŸ” Testing variant: 'ALL STORES'\n         ğŸ” Testing variant: 'allstores'\n         ğŸ” Testing variant: 'all(stores'\n         ğŸ” Testing variant: 'ALLSTORES'\n         ğŸ” Testing variant: 'all_stores'\n         ğŸ” Testing variant: 'ALL_STORES'\n         ğŸ” Testing variant: 'All Stores'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['stores', 'of', 'heb'] (positions 2-4)\n         ğŸ” Testing variant: 'stores of heb'\n         ğŸ” Testing variant: 'STORES OF HEB'\n         ğŸ” Testing variant: 'storesofheb'\n         ğŸ” Testing variant: 'stores(of(heb'\n         ğŸ” Testing variant: 'STORESOFHEB'\n         ğŸ” Testing variant: 'stores_of_heb'\n         ğŸ” Testing variant: 'STORES_OF_HEB'\n         ğŸ” Testing variant: 'Stores Of Heb'\n      ğŸ” Testing combination: ['stores', 'of'] (positions 2-3)\n         ğŸ” Testing variant: 'stores of'\n         ğŸ” Testing variant: 'STORES OF'\n         ğŸ” Testing variant: 'storesof'\n         ğŸ” Testing variant: 'stores(of'\n         ğŸ” Testing variant: 'STORESOF'\n         ğŸ” Testing variant: 'stores_of'\n         ğŸ” Testing variant: 'STORES_OF'\n         ğŸ” Testing variant: 'Stores Of'\n      ğŸ” Testing combination: ['stores'] (positions 2-2)\n         ğŸ” Testing variant: 'stores'\n         ğŸ” Testing variant: 'STORES'\n         ğŸ” Testing variant: 'Stores'\n      ğŸ” Testing combination: ['of', 'heb'] (positions 3-4)\n         ğŸ” Testing variant: 'of heb'\n         ğŸ” Testing variant: 'OF HEB'\n         ğŸ” Testing variant: 'ofheb'\n         ğŸ” Testing variant: 'of(heb'\n         ğŸ” Testing variant: 'OFHEB'\n         ğŸ” Testing variant: 'of_heb'\n         ğŸ” Testing variant: 'OF_HEB'\n         ğŸ” Testing variant: 'Of Heb'\n      ğŸ” Testing combination: ['of'] (positions 3-3)\n         ğŸ” Testing variant: 'of'\n         ğŸ” Testing variant: 'OF'\n         ğŸ” Testing variant: 'Of'\n      ğŸ” Testing combination: ['heb'] (positions 4-4)\n         ğŸ” Testing variant: 'heb'\n         âœ… MATCH FOUND: 'heb' â†’ {'original_value': 'HEB', 'column_name': 'Account', 'column_type': 'dimension', 'variants': ['HEB', 'heb'], 'confidence': 1.0}\n         ğŸ§  Analyzing context for implicit value...\n            ğŸ“ Before: ['list', 'all', 'stores', 'of']\n            ğŸ“ After: []\n            ğŸ“‹ Value column: account\n            âœ… SELECTION pattern detected\n      âœ… IMPLICIT VALUE DETECTED:\n         ğŸ“ Value: 'HEB'\n         ğŸ“‹ Column: Account\n         ğŸ¯ Context: SELECTION_PATTERN\n         â­ Confidence: 0.90\n         ğŸ”’ Positions processed: [4]\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 1\nğŸ”’ TOTAL POSITIONS PROCESSED: [4]\n   âœ… Implicit filters found: 1\n      ğŸ” account = 'HEB' (confidence: 0.90)\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: [4]\nğŸ” Testing TEMPORAL DICT pattern: 'stores' + [value from dictionary]\n      ğŸ—„ï¸ Searching temporal dictionary starting at position 3\n         ğŸ” Testing 2 tokens: ['of', 'heb']\n            ğŸ” Testing variant: 'of heb'\n            ğŸ” Testing variant: 'ofheb'\n            ğŸ” Testing variant: 'of_heb'\n            ğŸ” Testing variant: 'OF HEB'\n            ğŸ” Testing variant: 'OFHEB'\n            ğŸ” Testing variant: 'OF_HEB'\n         ğŸ” Testing 1 tokens: ['of']\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'of'\n            ğŸ” Testing variant: 'OF'\n            ğŸ” Testing variant: 'OF'\n            ğŸ” Testing variant: 'OF'\n         âŒ No matches found in temporal dictionary\nâ­• PREPOSITION PATTERN: positions {2, 3, 4} overlap with processed {4}\nğŸ¯ Total filters detected: 1\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 1\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: [4]\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 1\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âŒ No temporal dimension at start: 'list'\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'stores'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\nğŸ“‹ DEBUG: list_all_pattern = True\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ”— English filter detected: account = 'HEB'\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'stores' classified as dimension\nğŸ” English token 'of' classified as connector\nğŸ¯ English token 'heb' classified as value (used in filter)\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'stores'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\n   ğŸ“‹ List all pattern detected: True\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   âŒ No temporal dimension at start: 'list'\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'stores')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores', 'of', 'heb']\n   ğŸ“Š Segments detected: [['list', 'all', 'stores', 'of', 'heb']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'stores', 'of', 'heb']\n      ğŸ” Analyzing English segment: ['list', 'all', 'stores', 'of', 'heb']\n         ğŸ“ English dimension candidate: stores\n         ğŸ”„ English dimension converted to metric: stores\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: stores\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: stores\n   ğŸ“‹ Structure marked as LIST_ALL\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: stores\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all stores of heb'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: True\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: True\n   ğŸ“‹ LIST_ALL pattern detected - using special validation\n   âœ… LIST_ALL validation passed - target: stores\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = True\nğŸ”§ DEBUG: list_all_pattern value = {'pattern_type': 'LIST_ALL', 'list_indicator': 'list', 'has_all_indicator': True, 'all_indicator': 'all', 'target_dimension': 'stores', 'has_aggregation': False, 'confidence': 0.9999999999999999, 'raw_tokens': ['list', 'all', 'stores', 'of', 'heb'], 'is_temporal_list': False}\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“‹ DETECTED: Enhanced English list all â†’ using ENHANCED specialized generator\nğŸ“‹ GENERATING ENHANCED LIST ALL SQL (WITH DISTINCT/GROUP BY LOGIC):\n   ğŸ“‹ List type: list\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   ğŸ“‹ Simple list - using DISTINCT\n   âœ… Using DISTINCT for unique values\n   âœ… Column filter: account = 'HEB'\n   â° Processing temporal conditions for LIST ALL...\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   â° Found 0 temporal conditions\n   ğŸ¯ Enhanced LIST ALL SQL: SELECT DISTINCT stores FROM datos WHERE account = 'HEB' ORDER BY stores;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT DISTINCT stores FROM datos WHERE account = 'HEB' ORDER BY stores;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT DISTINCT stores FROM datos WHERE account = 'HEB' ORDER BY stores;\n      ğŸ” Searching for 'stores' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n      âœ… Dimension match: 'stores' â†’ 'Store' (list structure)\n   ğŸ”„ Standalone mapping: 'stores' â†’ Store\n      ğŸ” Searching for 'account' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n      âœ… Dimension match: 'account' â†’ 'Account' (list structure)\n   ğŸ”„ Standalone mapping: 'account' â†’ Account\n      ğŸ” Searching for 'HEB' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sell_through' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sales_amount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'order_number' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'profit' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'margin' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'quantity' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Inventory' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'price' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'cost' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'orders' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'transactions' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_8w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_4w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Week' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'roi' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'discount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'revenue' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Venta_perdida' (data type: <class 'list'>)\n      âŒ No mapping found for 'HEB'\n      ğŸ” DEBUG - Sample dimension_anchors structure:\n         'employee': <class 'list'> = ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal', 'staff', 'agente', 'agentes', 'representante', 'representantes', 'ejecutivo', 'ejecutivos', 'asesor', 'asesores', 'colaborador', 'colaboradores', 'trabajador', 'trabajadores', 'operador', 'operadores', 'consultor', 'consultores', 'employee', 'employees', 'worker', 'workers', 'staff', 'personnel', 'agent', 'agents', 'representative', 'representatives', 'executive', 'executives', 'advisor', 'advisors', 'consultant', 'consultants', 'operator', 'operators', 'associate', 'associates', 'team_member', 'team_members', 'crew', 'workforce', 'human_resource', 'human_resources']\n         'category': <class 'list'> = ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat', 'cats', 'clasificacion', 'clasificaciones', 'clasificaciÃ³n', 'segmento', 'segmentos', 'division', 'divisiones', 'divisiÃ³n', 'category', 'categories', 'classification', 'classifications', 'segment', 'segments', 'division', 'divisions', 'group', 'groups', 'type', 'types', 'kind', 'kinds', 'class', 'classes', 'section', 'sections', 'grouping', 'groupings']\n         'brand': <class 'list'> = ['marca', 'marcas', 'brand', 'brands', 'etiqueta', 'etiquetas', 'label', 'labels', 'fabricante', 'fabricantes', 'proveedor_marca', 'casa', 'casas', 'firma', 'firmas', 'nombre_comercial', 'manufacturer', 'manufacturers', 'maker', 'makers', 'producer', 'producers', 'supplier', 'suppliers', 'vendor', 'vendors', 'company', 'companies', 'trademark', 'trademarks', 'brandname', 'brandnames', 'marque', 'logo']\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT DISTINCT Store FROM datos WHERE Account = 'HEB' ORDER BY Store;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 39\n      ğŸ“ Added quotes: Store â†’ \"Store\" at position 66\n      ğŸ“ Added quotes: Store â†’ \"Store\" at position 16\n   ğŸ“¤ Output: SELECT DISTINCT \"Store\" FROM datos WHERE \"Account\" = 'HEB' ORDER BY \"Store\";\n   ğŸ“Š Reemplazos realizados: 3\n   ğŸ“¤ Output: SELECT DISTINCT \"Store\" FROM datos WHERE \"Account\" = 'HEB' ORDER BY \"Store\";\n   ğŸ“Š Reemplazos realizados: 2\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT DISTINCT \"Store\" FROM datos WHERE \"Account\" = 'HEB' ORDER BY \"Store\";'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: stores\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Conservando filtro: account = HEB\n   âœ… Parte principal: (stores) con (account = 'HEB')\n   ğŸ¯ Resultado final COMPUESTO: (stores) con (account = 'HEB')\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT DISTINCT \"Store\" FROM datos WHERE \"Account\" = 'HEB' ORDER BY \"Store\";'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:44:39.387798",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:44:39.387721",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all Ã­tems sold by heb'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all Ã­tems sold by heb'\nğŸ” DEBUG: Query con placeholders: 'list all Ã­tems sold by heb'\nğŸ” DEBUG: Text en minÃºsculas: 'list all Ã­tems sold by heb'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all Ã­tems sold by heb'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all Ã­tems sold by heb'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all Ã­tems sold by heb'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all Ã­tems sold by heb'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'by' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 20 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all Ã­tems sold by heb'\nğŸ”§ Normalizing English query: 'list all Ã­tems sold by heb'\nâœ… English normalized: 'list all Ã­tems sold by heb'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'Ã­tems' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   ğŸ“ Total tokens: 6\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb'] (positions 0-5)\n         ğŸ” Testing variant: 'list all Ã­tems sold by heb'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS SOLD BY HEB'\n         ğŸ” Testing variant: 'listallÃ­temssoldbyheb'\n         ğŸ” Testing variant: 'list(all(Ã­tems(sold(by(heb'\n         ğŸ” Testing variant: 'LISTALLÃTEMSSOLDBYHEB'\n         ğŸ” Testing variant: 'list_all_Ã­tems_sold_by_heb'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS_SOLD_BY_HEB'\n         ğŸ” Testing variant: 'List All Ãtems Sold By Heb'\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems', 'sold', 'by'] (positions 0-4)\n         ğŸ” Testing variant: 'list all Ã­tems sold by'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS SOLD BY'\n         ğŸ” Testing variant: 'listallÃ­temssoldby'\n         ğŸ” Testing variant: 'list(all(Ã­tems(sold(by'\n         ğŸ” Testing variant: 'LISTALLÃTEMSSOLDBY'\n         ğŸ” Testing variant: 'list_all_Ã­tems_sold_by'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS_SOLD_BY'\n         ğŸ” Testing variant: 'List All Ãtems Sold By'\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems', 'sold'] (positions 0-3)\n         ğŸ” Testing variant: 'list all Ã­tems sold'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS SOLD'\n         ğŸ” Testing variant: 'listallÃ­temssold'\n         ğŸ” Testing variant: 'list(all(Ã­tems(sold'\n         ğŸ” Testing variant: 'LISTALLÃTEMSSOLD'\n         ğŸ” Testing variant: 'list_all_Ã­tems_sold'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS_SOLD'\n         ğŸ” Testing variant: 'List All Ãtems Sold'\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems'] (positions 0-2)\n         ğŸ” Testing variant: 'list all Ã­tems'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS'\n         ğŸ” Testing variant: 'listallÃ­tems'\n         ğŸ” Testing variant: 'list(all(Ã­tems'\n         ğŸ” Testing variant: 'LISTALLÃTEMS'\n         ğŸ” Testing variant: 'list_all_Ã­tems'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS'\n         ğŸ” Testing variant: 'List All Ãtems'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'Ã­tems', 'sold', 'by', 'heb'] (positions 1-5)\n         ğŸ” Testing variant: 'all Ã­tems sold by heb'\n         ğŸ” Testing variant: 'ALL ÃTEMS SOLD BY HEB'\n         ğŸ” Testing variant: 'allÃ­temssoldbyheb'\n         ğŸ” Testing variant: 'all(Ã­tems(sold(by(heb'\n         ğŸ” Testing variant: 'ALLÃTEMSSOLDBYHEB'\n         ğŸ” Testing variant: 'all_Ã­tems_sold_by_heb'\n         ğŸ” Testing variant: 'ALL_ÃTEMS_SOLD_BY_HEB'\n         ğŸ” Testing variant: 'All Ãtems Sold By Heb'\n      ğŸ” Testing combination: ['all', 'Ã­tems', 'sold', 'by'] (positions 1-4)\n         ğŸ” Testing variant: 'all Ã­tems sold by'\n         ğŸ” Testing variant: 'ALL ÃTEMS SOLD BY'\n         ğŸ” Testing variant: 'allÃ­temssoldby'\n         ğŸ” Testing variant: 'all(Ã­tems(sold(by'\n         ğŸ” Testing variant: 'ALLÃTEMSSOLDBY'\n         ğŸ” Testing variant: 'all_Ã­tems_sold_by'\n         ğŸ” Testing variant: 'ALL_ÃTEMS_SOLD_BY'\n         ğŸ” Testing variant: 'All Ãtems Sold By'\n      ğŸ” Testing combination: ['all', 'Ã­tems', 'sold'] (positions 1-3)\n         ğŸ” Testing variant: 'all Ã­tems sold'\n         ğŸ” Testing variant: 'ALL ÃTEMS SOLD'\n         ğŸ” Testing variant: 'allÃ­temssold'\n         ğŸ” Testing variant: 'all(Ã­tems(sold'\n         ğŸ” Testing variant: 'ALLÃTEMSSOLD'\n         ğŸ” Testing variant: 'all_Ã­tems_sold'\n         ğŸ” Testing variant: 'ALL_ÃTEMS_SOLD'\n         ğŸ” Testing variant: 'All Ãtems Sold'\n      ğŸ” Testing combination: ['all', 'Ã­tems'] (positions 1-2)\n         ğŸ” Testing variant: 'all Ã­tems'\n         ğŸ” Testing variant: 'ALL ÃTEMS'\n         ğŸ” Testing variant: 'allÃ­tems'\n         ğŸ” Testing variant: 'all(Ã­tems'\n         ğŸ” Testing variant: 'ALLÃTEMS'\n         ğŸ” Testing variant: 'all_Ã­tems'\n         ğŸ” Testing variant: 'ALL_ÃTEMS'\n         ğŸ” Testing variant: 'All Ãtems'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['Ã­tems', 'sold', 'by', 'heb'] (positions 2-5)\n         ğŸ” Testing variant: 'Ã­tems sold by heb'\n         ğŸ” Testing variant: 'ÃTEMS SOLD BY HEB'\n         ğŸ” Testing variant: 'Ã­temssoldbyheb'\n         ğŸ” Testing variant: 'Ã­tems(sold(by(heb'\n         ğŸ” Testing variant: 'ÃTEMSSOLDBYHEB'\n         ğŸ” Testing variant: 'Ã­tems_sold_by_heb'\n         ğŸ” Testing variant: 'ÃTEMS_SOLD_BY_HEB'\n         ğŸ” Testing variant: 'Ãtems Sold By Heb'\n      ğŸ” Testing combination: ['Ã­tems', 'sold', 'by'] (positions 2-4)\n         ğŸ” Testing variant: 'Ã­tems sold by'\n         ğŸ” Testing variant: 'ÃTEMS SOLD BY'\n         ğŸ” Testing variant: 'Ã­temssoldby'\n         ğŸ” Testing variant: 'Ã­tems(sold(by'\n         ğŸ” Testing variant: 'ÃTEMSSOLDBY'\n         ğŸ” Testing variant: 'Ã­tems_sold_by'\n         ğŸ” Testing variant: 'ÃTEMS_SOLD_BY'\n         ğŸ” Testing variant: 'Ãtems Sold By'\n      ğŸ” Testing combination: ['Ã­tems', 'sold'] (positions 2-3)\n         ğŸ” Testing variant: 'Ã­tems sold'\n         ğŸ” Testing variant: 'ÃTEMS SOLD'\n         ğŸ” Testing variant: 'Ã­temssold'\n         ğŸ” Testing variant: 'Ã­tems(sold'\n         ğŸ” Testing variant: 'ÃTEMSSOLD'\n         ğŸ” Testing variant: 'Ã­tems_sold'\n         ğŸ” Testing variant: 'ÃTEMS_SOLD'\n         ğŸ” Testing variant: 'Ãtems Sold'\n      ğŸ” Testing combination: ['Ã­tems'] (positions 2-2)\n         ğŸ” Testing variant: 'Ã­tems'\n         ğŸ” Testing variant: 'ÃTEMS'\n         ğŸ” Testing variant: 'Ãtems'\n      ğŸ” Testing combination: ['sold', 'by', 'heb'] (positions 3-5)\n         ğŸ” Testing variant: 'sold by heb'\n         ğŸ” Testing variant: 'SOLD BY HEB'\n         ğŸ” Testing variant: 'soldbyheb'\n         ğŸ” Testing variant: 'sold(by(heb'\n         ğŸ” Testing variant: 'SOLDBYHEB'\n         ğŸ” Testing variant: 'sold_by_heb'\n         ğŸ” Testing variant: 'SOLD_BY_HEB'\n         ğŸ” Testing variant: 'Sold By Heb'\n      ğŸ” Testing combination: ['sold', 'by'] (positions 3-4)\n         ğŸ” Testing variant: 'sold by'\n         ğŸ” Testing variant: 'SOLD BY'\n         ğŸ” Testing variant: 'soldby'\n         ğŸ” Testing variant: 'sold(by'\n         ğŸ” Testing variant: 'SOLDBY'\n         ğŸ” Testing variant: 'sold_by'\n         ğŸ” Testing variant: 'SOLD_BY'\n         ğŸ” Testing variant: 'Sold By'\n      ğŸ” Testing combination: ['sold'] (positions 3-3)\n         ğŸ” Testing variant: 'sold'\n         ğŸ” Testing variant: 'SOLD'\n         ğŸ” Testing variant: 'Sold'\n      ğŸ” Testing combination: ['by', 'heb'] (positions 4-5)\n         ğŸ” Testing variant: 'by heb'\n         ğŸ” Testing variant: 'BY HEB'\n         ğŸ” Testing variant: 'byheb'\n         ğŸ” Testing variant: 'by(heb'\n         ğŸ” Testing variant: 'BYHEB'\n         ğŸ” Testing variant: 'by_heb'\n         ğŸ” Testing variant: 'BY_HEB'\n         ğŸ” Testing variant: 'By Heb'\n      ğŸ” Testing combination: ['by'] (positions 4-4)\n         ğŸ” Testing variant: 'by'\n         ğŸ” Testing variant: 'BY'\n         ğŸ” Testing variant: 'By'\n      ğŸ” Testing combination: ['heb'] (positions 5-5)\n         ğŸ” Testing variant: 'heb'\n         âœ… MATCH FOUND: 'heb' â†’ {'original_value': 'HEB', 'column_name': 'Account', 'column_type': 'dimension', 'variants': ['HEB', 'heb'], 'confidence': 1.0}\n         ğŸ§  Analyzing context for implicit value...\n            ğŸ“ Before: ['list', 'all', 'Ã­tems', 'sold', 'by']\n            ğŸ“ After: []\n            ğŸ“‹ Value column: account\n            âœ… SELECTION pattern detected\n      âœ… IMPLICIT VALUE DETECTED:\n         ğŸ“ Value: 'HEB'\n         ğŸ“‹ Column: Account\n         ğŸ¯ Context: SELECTION_PATTERN\n         â­ Confidence: 0.90\n         ğŸ”’ Positions processed: [5]\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 1\nğŸ”’ TOTAL POSITIONS PROCESSED: [5]\n   âœ… Implicit filters found: 1\n      ğŸ” account = 'HEB' (confidence: 0.90)\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: [5]\nğŸ” Testing TEMPORAL DICT pattern: 'sold' + [value from dictionary]\n      ğŸ—„ï¸ Searching temporal dictionary starting at position 4\n         ğŸ” Testing 2 tokens: ['by', 'heb']\n            ğŸ” Testing variant: 'by heb'\n            ğŸ” Testing variant: 'byheb'\n            ğŸ” Testing variant: 'by_heb'\n            ğŸ” Testing variant: 'BY HEB'\n            ğŸ” Testing variant: 'BYHEB'\n            ğŸ” Testing variant: 'BY_HEB'\n         ğŸ” Testing 1 tokens: ['by']\n            ğŸ” Testing variant: 'by'\n            ğŸ” Testing variant: 'by'\n            ğŸ” Testing variant: 'by'\n            ğŸ” Testing variant: 'BY'\n            ğŸ” Testing variant: 'BY'\n            ğŸ” Testing variant: 'BY'\n         âŒ No matches found in temporal dictionary\nâ­• PREPOSITION PATTERN: positions {3, 4, 5} overlap with processed {5}\nğŸ¯ Total filters detected: 1\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 1\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: [5]\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 1\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No temporal dimension at start: 'list'\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ”— English filter detected: account = 'HEB'\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'Ã­tems' classified as unknown\nğŸ” English token 'sold' classified as metric\nğŸ” English token 'by' classified as connector\nğŸ¯ English token 'heb' classified as value (used in filter)\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No temporal dimension at start: 'list'\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   ğŸ“Š Segments detected: [['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n      ğŸ” Analyzing English segment: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n         ğŸ“Š English REAL metric found: sold\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: sold\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“Š English metric: sold\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: ['sold']\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ¯ IMPLICIT DIMENSION from filter: account\n   ğŸ“Š ENGLISH PATTERN: AGGREGATION (metric of value)\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'sold', 'by', 'heb']\n   âŒ No question word found\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all Ã­tems sold by heb'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 1\n   ğŸ¯ Query pattern: aggregation\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': True, 'error': None, 'suggestions': ['English unrecognized words: list, Ã­tems']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': ['English unrecognized words: list, Ã­tems']}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ—„ï¸ Generating OPTIMIZED English SQL:\n   â° Temporal columns detected: set()\n   ğŸ¯ Query pattern: aggregation\n   ğŸ”— Is compound: False\n   ğŸ† Is ranking: False\n   ğŸ”— Is multi-dimensional: False\nğŸ”§ GROUP BY dimension with metrics detected - adding aggregations\n   ğŸ“Š No operation found, using default SUM for metric 'sold'\n   âœ… Added to GROUP BY query: SUM(sold)\n   âœ… English WHERE condition: account = 'HEB'\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   ğŸ¯ Final OPTIMIZED English SQL: SELECT account, SUM(sold) FROM datos WHERE account = 'HEB' GROUP BY account ORDER BY SUM(sold) DESC;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT account, SUM(sold) FROM datos WHERE account = 'HEB' GROUP BY account ORDER BY SUM(sold) DESC;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT account, SUM(sold) FROM datos WHERE account = 'HEB' GROUP BY account ORDER BY SUM(sold) DESC;\n   ğŸ” Function found: SUM(sold)\n      ğŸ” Searching for 'sold' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sold' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sold) â†’ SUM(Sell_Out)\n   ğŸ” Function found: SUM(sold)\n      ğŸ” Searching for 'sold' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n      âœ… Metric match: 'sold' â†’ 'Sell_Out' (list structure)\n   ğŸ”„ Function mapping: SUM(sold) â†’ SUM(Sell_Out)\n      ğŸ” Searching for 'account' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n      âœ… Dimension match: 'account' â†’ 'Account' (list structure)\n   ğŸ”„ Standalone mapping: 'account' â†’ Account\n      ğŸ” Searching for 'HEB' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sell_through' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sales_amount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'order_number' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'profit' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'margin' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'quantity' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Inventory' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'price' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'cost' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'orders' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'transactions' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_8w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_4w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Week' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'roi' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'discount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'revenue' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Venta_perdida' (data type: <class 'list'>)\n      âŒ No mapping found for 'HEB'\n      ğŸ” DEBUG - Sample dimension_anchors structure:\n         'employee': <class 'list'> = ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal', 'staff', 'agente', 'agentes', 'representante', 'representantes', 'ejecutivo', 'ejecutivos', 'asesor', 'asesores', 'colaborador', 'colaboradores', 'trabajador', 'trabajadores', 'operador', 'operadores', 'consultor', 'consultores', 'employee', 'employees', 'worker', 'workers', 'staff', 'personnel', 'agent', 'agents', 'representative', 'representatives', 'executive', 'executives', 'advisor', 'advisors', 'consultant', 'consultants', 'operator', 'operators', 'associate', 'associates', 'team_member', 'team_members', 'crew', 'workforce', 'human_resource', 'human_resources']\n         'category': <class 'list'> = ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat', 'cats', 'clasificacion', 'clasificaciones', 'clasificaciÃ³n', 'segmento', 'segmentos', 'division', 'divisiones', 'divisiÃ³n', 'category', 'categories', 'classification', 'classifications', 'segment', 'segments', 'division', 'divisions', 'group', 'groups', 'type', 'types', 'kind', 'kinds', 'class', 'classes', 'section', 'sections', 'grouping', 'groupings']\n         'brand': <class 'list'> = ['marca', 'marcas', 'brand', 'brands', 'etiqueta', 'etiquetas', 'label', 'labels', 'fabricante', 'fabricantes', 'proveedor_marca', 'casa', 'casas', 'firma', 'firmas', 'nombre_comercial', 'manufacturer', 'manufacturers', 'maker', 'makers', 'producer', 'producers', 'supplier', 'suppliers', 'vendor', 'vendors', 'company', 'companies', 'trademark', 'trademarks', 'brandname', 'brandnames', 'marque', 'logo']\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT Account, SUM(Sell_Out) FROM datos WHERE Account = 'HEB' GROUP BY Account ORDER BY SUM(Sell_Out) DESC;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 93\n      ğŸ“ Added quotes: Sell_Out â†’ \"Sell_Out\" at position 20\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 74\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 49\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 7\n   ğŸ“¤ Output: SELECT \"Account\", SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB' GROUP BY \"Account\" ORDER BY SUM(\"Sell_Out\") DESC;\n   ğŸ“Š Reemplazos realizados: 5\n   ğŸ“¤ Output: SELECT \"Account\", SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB' GROUP BY \"Account\" ORDER BY SUM(\"Sell_Out\") DESC;\n   ğŸ“Š Reemplazos realizados: 3\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT \"Account\", SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB' GROUP BY \"Account\" ORDER BY SUM(\"Sell_Out\") DESC;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: account\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? True\n   âœ… Conservando filtro: account = HEB\n   âœ… Filtros directos (no temporales): [\"(account = 'HEB')\"]\n   ğŸ”§ CombinaciÃ³n estÃ¡ndar (mÃºltiples condiciones): (account = 'HEB') Y (sold)\n   ğŸ¯ Resultado final COMPUESTO: (account = 'HEB') Y (sold)\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT \"Account\", SUM(\"Sell_Out\") FROM datos WHERE \"Account\" = 'HEB' GROUP BY \"Account\" ORDER BY SUM(\"Sell_Out\") DESC;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:44:54.062377",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:44:54.062314",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all Ã­tems in heb'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all Ã­tems in heb'\nğŸ” DEBUG: Query con placeholders: 'list all Ã­tems in heb'\nğŸ” DEBUG: Text en minÃºsculas: 'list all Ã­tems in heb'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all Ã­tems in heb'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all Ã­tems in heb'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all Ã­tems in heb'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all Ã­tems in heb'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'Ã­tems', 'in', 'heb']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'in' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 20 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all Ã­tems in heb'\nğŸ”§ Normalizing English query: 'list all Ã­tems in heb'\nâœ… English normalized: 'list all Ã­tems in heb'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'Ã­tems' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   ğŸ“ Total tokens: 5\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems', 'in', 'heb'] (positions 0-4)\n         ğŸ” Testing variant: 'list all Ã­tems in heb'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS IN HEB'\n         ğŸ” Testing variant: 'listallÃ­temsinheb'\n         ğŸ” Testing variant: 'list(all(Ã­tems(in(heb'\n         ğŸ” Testing variant: 'LISTALLÃTEMSINHEB'\n         ğŸ” Testing variant: 'list_all_Ã­tems_in_heb'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS_IN_HEB'\n         ğŸ” Testing variant: 'List All Ãtems In Heb'\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems', 'in'] (positions 0-3)\n         ğŸ” Testing variant: 'list all Ã­tems in'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS IN'\n         ğŸ” Testing variant: 'listallÃ­temsin'\n         ğŸ” Testing variant: 'list(all(Ã­tems(in'\n         ğŸ” Testing variant: 'LISTALLÃTEMSIN'\n         ğŸ” Testing variant: 'list_all_Ã­tems_in'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS_IN'\n         ğŸ” Testing variant: 'List All Ãtems In'\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems'] (positions 0-2)\n         ğŸ” Testing variant: 'list all Ã­tems'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS'\n         ğŸ” Testing variant: 'listallÃ­tems'\n         ğŸ” Testing variant: 'list(all(Ã­tems'\n         ğŸ” Testing variant: 'LISTALLÃTEMS'\n         ğŸ” Testing variant: 'list_all_Ã­tems'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS'\n         ğŸ” Testing variant: 'List All Ãtems'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'Ã­tems', 'in', 'heb'] (positions 1-4)\n         ğŸ” Testing variant: 'all Ã­tems in heb'\n         ğŸ” Testing variant: 'ALL ÃTEMS IN HEB'\n         ğŸ” Testing variant: 'allÃ­temsinheb'\n         ğŸ” Testing variant: 'all(Ã­tems(in(heb'\n         ğŸ” Testing variant: 'ALLÃTEMSINHEB'\n         ğŸ” Testing variant: 'all_Ã­tems_in_heb'\n         ğŸ” Testing variant: 'ALL_ÃTEMS_IN_HEB'\n         ğŸ” Testing variant: 'All Ãtems In Heb'\n      ğŸ” Testing combination: ['all', 'Ã­tems', 'in'] (positions 1-3)\n         ğŸ” Testing variant: 'all Ã­tems in'\n         ğŸ” Testing variant: 'ALL ÃTEMS IN'\n         ğŸ” Testing variant: 'allÃ­temsin'\n         ğŸ” Testing variant: 'all(Ã­tems(in'\n         ğŸ” Testing variant: 'ALLÃTEMSIN'\n         ğŸ” Testing variant: 'all_Ã­tems_in'\n         ğŸ” Testing variant: 'ALL_ÃTEMS_IN'\n         ğŸ” Testing variant: 'All Ãtems In'\n      ğŸ” Testing combination: ['all', 'Ã­tems'] (positions 1-2)\n         ğŸ” Testing variant: 'all Ã­tems'\n         ğŸ” Testing variant: 'ALL ÃTEMS'\n         ğŸ” Testing variant: 'allÃ­tems'\n         ğŸ” Testing variant: 'all(Ã­tems'\n         ğŸ” Testing variant: 'ALLÃTEMS'\n         ğŸ” Testing variant: 'all_Ã­tems'\n         ğŸ” Testing variant: 'ALL_ÃTEMS'\n         ğŸ” Testing variant: 'All Ãtems'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['Ã­tems', 'in', 'heb'] (positions 2-4)\n         ğŸ” Testing variant: 'Ã­tems in heb'\n         ğŸ” Testing variant: 'ÃTEMS IN HEB'\n         ğŸ” Testing variant: 'Ã­temsinheb'\n         ğŸ” Testing variant: 'Ã­tems(in(heb'\n         ğŸ” Testing variant: 'ÃTEMSINHEB'\n         ğŸ” Testing variant: 'Ã­tems_in_heb'\n         ğŸ” Testing variant: 'ÃTEMS_IN_HEB'\n         ğŸ” Testing variant: 'Ãtems In Heb'\n      ğŸ” Testing combination: ['Ã­tems', 'in'] (positions 2-3)\n         ğŸ” Testing variant: 'Ã­tems in'\n         ğŸ” Testing variant: 'ÃTEMS IN'\n         ğŸ” Testing variant: 'Ã­temsin'\n         ğŸ” Testing variant: 'Ã­tems(in'\n         ğŸ” Testing variant: 'ÃTEMSIN'\n         ğŸ” Testing variant: 'Ã­tems_in'\n         ğŸ” Testing variant: 'ÃTEMS_IN'\n         ğŸ” Testing variant: 'Ãtems In'\n      ğŸ” Testing combination: ['Ã­tems'] (positions 2-2)\n         ğŸ” Testing variant: 'Ã­tems'\n         ğŸ” Testing variant: 'ÃTEMS'\n         ğŸ” Testing variant: 'Ãtems'\n      ğŸ” Testing combination: ['in', 'heb'] (positions 3-4)\n         ğŸ” Testing variant: 'in heb'\n         ğŸ” Testing variant: 'IN HEB'\n         ğŸ” Testing variant: 'inheb'\n         ğŸ” Testing variant: 'in(heb'\n         ğŸ” Testing variant: 'INHEB'\n         ğŸ” Testing variant: 'in_heb'\n         ğŸ” Testing variant: 'IN_HEB'\n         ğŸ” Testing variant: 'In Heb'\n      ğŸ” Testing combination: ['in'] (positions 3-3)\n         ğŸ” Testing variant: 'in'\n         ğŸ” Testing variant: 'IN'\n         ğŸ” Testing variant: 'In'\n      ğŸ” Testing combination: ['heb'] (positions 4-4)\n         ğŸ” Testing variant: 'heb'\n         âœ… MATCH FOUND: 'heb' â†’ {'original_value': 'HEB', 'column_name': 'Account', 'column_type': 'dimension', 'variants': ['HEB', 'heb'], 'confidence': 1.0}\n         ğŸ§  Analyzing context for implicit value...\n            ğŸ“ Before: ['list', 'all', 'Ã­tems', 'in']\n            ğŸ“ After: []\n            ğŸ“‹ Value column: account\n            âœ… SELECTION pattern detected\n      âœ… IMPLICIT VALUE DETECTED:\n         ğŸ“ Value: 'HEB'\n         ğŸ“‹ Column: Account\n         ğŸ¯ Context: SELECTION_PATTERN\n         â­ Confidence: 0.90\n         ğŸ”’ Positions processed: [4]\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 1\nğŸ”’ TOTAL POSITIONS PROCESSED: [4]\n   âœ… Implicit filters found: 1\n      ğŸ” account = 'HEB' (confidence: 0.90)\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: [4]\nâ­• PREPOSITION PATTERN: positions {2, 3, 4} overlap with processed {4}\nğŸ¯ Total filters detected: 1\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 1\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: [4]\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 1\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No temporal dimension at start: 'list'\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ”— English filter detected: account = 'HEB'\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'Ã­tems' classified as unknown\nğŸ” English token 'in' classified as connector\nğŸ¯ English token 'heb' classified as value (used in filter)\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No temporal dimension at start: 'list'\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   ğŸ“Š Segments detected: [['list', 'all', 'Ã­tems', 'in', 'heb']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'Ã­tems', 'in', 'heb']\n      ğŸ” Analyzing English segment: ['list', 'all', 'Ã­tems', 'in', 'heb']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   â“ ENGLISH PATTERN: UNKNOWN\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems', 'in', 'heb']\n   âŒ No question word found\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all Ã­tems in heb'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: unknown\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing main dimension', 'suggestions': ['English columns detected: account', 'Add an entity like: store, account, product, customer', 'English unrecognized words: list, Ã­tems']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing main dimension', 'suggestions': ['English columns detected: account', 'Add an entity like: store, account, product, customer', 'English unrecognized words: list, Ã­tems']}",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:45:11.261968",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: list all stores",
    "session_time": 3478.488485
  },
  {
    "timestamp": "2025-12-14T03:45:11.262001",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 3478.488518
  },
  {
    "timestamp": "2025-12-14T03:45:11.262037",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 3478.488554
  },
  {
    "timestamp": "2025-12-14T03:45:11.262043",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 3478.48856
  },
  {
    "timestamp": "2025-12-14T03:45:11.262048",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'list all stores'",
    "session_time": 3478.488565
  },
  {
    "timestamp": "2025-12-14T03:45:11.262054",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 3478.488571
  },
  {
    "timestamp": "2025-12-14T03:45:11.262060",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 3478.488577
  },
  {
    "timestamp": "2025-12-14T03:45:11.264261",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:45:11.264252",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all stores'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all stores'\nğŸ” DEBUG: Query con placeholders: 'list all stores'\nğŸ” DEBUG: Text en minÃºsculas: 'list all stores'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all stores'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all stores'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all stores'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all stores'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'stores']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'stores']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all stores'\nğŸ”§ Normalizing English query: 'list all stores'\nâœ… English normalized: 'list all stores'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'stores']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'stores']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'stores' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'stores']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'stores'] (positions 0-2)\n         ğŸ” Testing variant: 'list all stores'\n         ğŸ” Testing variant: 'LIST ALL STORES'\n         ğŸ” Testing variant: 'listallstores'\n         ğŸ” Testing variant: 'list(all(stores'\n         ğŸ” Testing variant: 'LISTALLSTORES'\n         ğŸ” Testing variant: 'list_all_stores'\n         ğŸ” Testing variant: 'LIST_ALL_STORES'\n         ğŸ” Testing variant: 'List All Stores'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'stores'] (positions 1-2)\n         ğŸ” Testing variant: 'all stores'\n         ğŸ” Testing variant: 'ALL STORES'\n         ğŸ” Testing variant: 'allstores'\n         ğŸ” Testing variant: 'all(stores'\n         ğŸ” Testing variant: 'ALLSTORES'\n         ğŸ” Testing variant: 'all_stores'\n         ğŸ” Testing variant: 'ALL_STORES'\n         ğŸ” Testing variant: 'All Stores'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['stores'] (positions 2-2)\n         ğŸ” Testing variant: 'stores'\n         ğŸ” Testing variant: 'STORES'\n         ğŸ” Testing variant: 'Stores'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'stores'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\nğŸ“‹ DEBUG: list_all_pattern = True\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'stores' classified as dimension\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'stores'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\n   ğŸ“‹ List all pattern detected: True\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'stores']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'stores')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'stores']\n   ğŸ“Š Segments detected: [['list', 'all', 'stores']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'stores']\n      ğŸ” Analyzing English segment: ['list', 'all', 'stores']\n         ğŸ“ English dimension candidate: stores\n         ğŸ”„ English dimension converted to metric: stores\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: stores\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: stores\n   ğŸ“‹ Structure marked as LIST_ALL\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: stores\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all stores'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: True\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: True\n   ğŸ“‹ LIST_ALL pattern detected - using special validation\n   âœ… LIST_ALL validation passed - target: stores\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = True\nğŸ”§ DEBUG: list_all_pattern value = {'pattern_type': 'LIST_ALL', 'list_indicator': 'list', 'has_all_indicator': True, 'all_indicator': 'all', 'target_dimension': 'stores', 'has_aggregation': False, 'confidence': 0.9999999999999999, 'raw_tokens': ['list', 'all', 'stores'], 'is_temporal_list': False}\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“‹ DETECTED: Enhanced English list all â†’ using ENHANCED specialized generator\nğŸ“‹ GENERATING ENHANCED LIST ALL SQL (WITH DISTINCT/GROUP BY LOGIC):\n   ğŸ“‹ List type: list\n   ğŸ“ Target dimension: stores\n   ğŸ“Š Has aggregation: False\n   ğŸ“‹ Simple list - using DISTINCT\n   âœ… Using DISTINCT for unique values\n   â° Processing temporal conditions for LIST ALL...\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   â° Found 0 temporal conditions\n   ğŸ¯ Enhanced LIST ALL SQL: SELECT DISTINCT stores FROM datos ORDER BY stores;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT DISTINCT stores FROM datos ORDER BY stores;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT DISTINCT stores FROM datos ORDER BY stores;\n      ğŸ” Searching for 'stores' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n      âœ… Dimension match: 'stores' â†’ 'Store' (list structure)\n   ğŸ”„ Standalone mapping: 'stores' â†’ Store\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT DISTINCT Store FROM datos ORDER BY Store;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Store â†’ \"Store\" at position 42\n      ğŸ“ Added quotes: Store â†’ \"Store\" at position 16\n   ğŸ“¤ Output: SELECT DISTINCT \"Store\" FROM datos ORDER BY \"Store\";\n   ğŸ“Š Reemplazos realizados: 2\n   ğŸ“¤ Output: SELECT DISTINCT \"Store\" FROM datos ORDER BY \"Store\";\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT DISTINCT \"Store\" FROM datos ORDER BY \"Store\";'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: stores\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Parte principal: (stores)\n   ğŸ¯ Resultado final COMPUESTO: (stores)\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT DISTINCT \"Store\" FROM datos ORDER BY \"Store\";'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:45:11.264268",
    "component": "nlp",
    "level": "info",
    "message": "âœ… Problemizador completado:",
    "session_time": 3478.490785
  },
  {
    "timestamp": "2025-12-14T03:45:11.264273",
    "component": "nlp",
    "level": "info",
    "message": "   ğŸ—„ï¸ SQL conceptual generado: SELECT DISTINCT \"Store\" FROM datos ORDER BY \"Store\";",
    "session_time": 3478.49079
  },
  {
    "timestamp": "2025-12-14T03:45:11.264294",
    "component": "nlp",
    "level": "info",
    "message": "âœ… SUCCESS: Procesando consulta (2ms)",
    "session_time": 3478.490811
  },
  {
    "timestamp": "2025-12-14T03:45:11.264300",
    "component": "exec",
    "level": "info",
    "message": "ğŸ—„ï¸ EJECUTANDO SQL - MODO: clickhouse",
    "session_time": 3478.490817
  },
  {
    "timestamp": "2025-12-14T03:45:11.264301",
    "component": "exec",
    "level": "info",
    "message": "   ğŸš€ Destino: ClickHouse (Motor Columnar)",
    "session_time": 3478.490818
  },
  {
    "timestamp": "2025-12-14T03:45:11.264304",
    "component": "exec",
    "level": "info",
    "message": "ğŸš€ PASO 3: EJECUCIÃ“N EN CLICKHOUSE",
    "session_time": 3478.490821
  },
  {
    "timestamp": "2025-12-14T03:45:11.802991",
    "component": "exec",
    "level": "info",
    "message": "âœ… Query ejecutada: 100 filas en 538ms",
    "session_time": 3479.029508
  },
  {
    "timestamp": "2025-12-14T03:45:11.804113",
    "component": "flask",
    "level": "info",
    "message": "âœ… Consulta Flask exitosa: 100 filas",
    "session_time": 3479.03063
  },
  {
    "timestamp": "2025-12-14T03:45:41.877941",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: lidt all acounts",
    "session_time": 3509.104458
  },
  {
    "timestamp": "2025-12-14T03:45:41.878035",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 3509.104552
  },
  {
    "timestamp": "2025-12-14T03:45:41.880210",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 3509.106727
  },
  {
    "timestamp": "2025-12-14T03:45:41.880256",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 3509.106773
  },
  {
    "timestamp": "2025-12-14T03:45:41.880269",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'lidt all acounts'",
    "session_time": 3509.106786
  },
  {
    "timestamp": "2025-12-14T03:45:41.880287",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 3509.106804
  },
  {
    "timestamp": "2025-12-14T03:45:41.880300",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 3509.106817
  },
  {
    "timestamp": "2025-12-14T03:45:41.884781",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:45:41.884749",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'lidt all acounts'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'lidt all acounts'\nğŸ” DEBUG: Query con placeholders: 'lidt all acounts'\nğŸ” DEBUG: Text en minÃºsculas: 'lidt all acounts'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'lidt all acounts'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'lidt all acounts'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'lidt all acounts'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'lidt all acounts'\nğŸ” TOKENS ORIGINALES: ['lidt', 'all', 'acounts']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['lidt', 'all', 'acounts']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'lidt all acounts'\nğŸ”§ Normalizing English query: 'lidt all acounts'\nâœ… English normalized: 'lidt all acounts'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['lidt', 'all', 'acounts']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['lidt', 'all', 'acounts']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'acounts' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['lidt', 'all', 'acounts']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['lidt', 'all', 'acounts'] (positions 0-2)\n         ğŸ” Testing variant: 'lidt all acounts'\n         ğŸ” Testing variant: 'LIDT ALL ACOUNTS'\n         ğŸ” Testing variant: 'lidtallacounts'\n         ğŸ” Testing variant: 'lidt(all(acounts'\n         ğŸ” Testing variant: 'LIDTALLACOUNTS'\n         ğŸ” Testing variant: 'lidt_all_acounts'\n         ğŸ” Testing variant: 'LIDT_ALL_ACOUNTS'\n         ğŸ” Testing variant: 'Lidt All Acounts'\n      ğŸ” Testing combination: ['lidt', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'lidt all'\n         ğŸ” Testing variant: 'LIDT ALL'\n         ğŸ” Testing variant: 'lidtall'\n         ğŸ” Testing variant: 'lidt(all'\n         ğŸ” Testing variant: 'LIDTALL'\n         ğŸ” Testing variant: 'lidt_all'\n         ğŸ” Testing variant: 'LIDT_ALL'\n         ğŸ” Testing variant: 'Lidt All'\n      ğŸ” Testing combination: ['lidt'] (positions 0-0)\n         ğŸ” Testing variant: 'lidt'\n         ğŸ” Testing variant: 'LIDT'\n         ğŸ” Testing variant: 'Lidt'\n      ğŸ” Testing combination: ['all', 'acounts'] (positions 1-2)\n         ğŸ” Testing variant: 'all acounts'\n         ğŸ” Testing variant: 'ALL ACOUNTS'\n         ğŸ” Testing variant: 'allacounts'\n         ğŸ” Testing variant: 'all(acounts'\n         ğŸ” Testing variant: 'ALLACOUNTS'\n         ğŸ” Testing variant: 'all_acounts'\n         ğŸ” Testing variant: 'ALL_ACOUNTS'\n         ğŸ” Testing variant: 'All Acounts'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['acounts'] (positions 2-2)\n         ğŸ” Testing variant: 'acounts'\n         ğŸ” Testing variant: 'ACOUNTS'\n         ğŸ” Testing variant: 'Acounts'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'lidt' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'acounts' classified as unknown\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   ğŸ“Š Segments detected: [['lidt', 'all', 'acounts']]\n\n   ğŸ¯ Processing English segment 1: ['lidt', 'all', 'acounts']\n      ğŸ” Analyzing English segment: ['lidt', 'all', 'acounts']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   â“ ENGLISH PATTERN: UNKNOWN\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'lidt all acounts'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: unknown\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: lidt, acounts']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: lidt, acounts']}",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:45:49.452828",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: lidt all acounts",
    "session_time": 3516.679345
  },
  {
    "timestamp": "2025-12-14T03:45:49.452944",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 3516.679461
  },
  {
    "timestamp": "2025-12-14T03:45:49.453001",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 3516.679518
  },
  {
    "timestamp": "2025-12-14T03:45:49.453011",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 3516.679528
  },
  {
    "timestamp": "2025-12-14T03:45:49.453020",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'lidt all acounts'",
    "session_time": 3516.679537
  },
  {
    "timestamp": "2025-12-14T03:45:49.453029",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 3516.679546
  },
  {
    "timestamp": "2025-12-14T03:45:49.453039",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 3516.679556
  },
  {
    "timestamp": "2025-12-14T03:45:49.457221",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:45:49.457193",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'lidt all acounts'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'lidt all acounts'\nğŸ” DEBUG: Query con placeholders: 'lidt all acounts'\nğŸ” DEBUG: Text en minÃºsculas: 'lidt all acounts'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'lidt all acounts'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'lidt all acounts'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'lidt all acounts'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'lidt all acounts'\nğŸ” TOKENS ORIGINALES: ['lidt', 'all', 'acounts']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['lidt', 'all', 'acounts']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'lidt all acounts'\nğŸ”§ Normalizing English query: 'lidt all acounts'\nâœ… English normalized: 'lidt all acounts'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['lidt', 'all', 'acounts']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['lidt', 'all', 'acounts']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'acounts' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['lidt', 'all', 'acounts']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['lidt', 'all', 'acounts'] (positions 0-2)\n         ğŸ” Testing variant: 'lidt all acounts'\n         ğŸ” Testing variant: 'LIDT ALL ACOUNTS'\n         ğŸ” Testing variant: 'lidtallacounts'\n         ğŸ” Testing variant: 'lidt(all(acounts'\n         ğŸ” Testing variant: 'LIDTALLACOUNTS'\n         ğŸ” Testing variant: 'lidt_all_acounts'\n         ğŸ” Testing variant: 'LIDT_ALL_ACOUNTS'\n         ğŸ” Testing variant: 'Lidt All Acounts'\n      ğŸ” Testing combination: ['lidt', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'lidt all'\n         ğŸ” Testing variant: 'LIDT ALL'\n         ğŸ” Testing variant: 'lidtall'\n         ğŸ” Testing variant: 'lidt(all'\n         ğŸ” Testing variant: 'LIDTALL'\n         ğŸ” Testing variant: 'lidt_all'\n         ğŸ” Testing variant: 'LIDT_ALL'\n         ğŸ” Testing variant: 'Lidt All'\n      ğŸ” Testing combination: ['lidt'] (positions 0-0)\n         ğŸ” Testing variant: 'lidt'\n         ğŸ” Testing variant: 'LIDT'\n         ğŸ” Testing variant: 'Lidt'\n      ğŸ” Testing combination: ['all', 'acounts'] (positions 1-2)\n         ğŸ” Testing variant: 'all acounts'\n         ğŸ” Testing variant: 'ALL ACOUNTS'\n         ğŸ” Testing variant: 'allacounts'\n         ğŸ” Testing variant: 'all(acounts'\n         ğŸ” Testing variant: 'ALLACOUNTS'\n         ğŸ” Testing variant: 'all_acounts'\n         ğŸ” Testing variant: 'ALL_ACOUNTS'\n         ğŸ” Testing variant: 'All Acounts'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['acounts'] (positions 2-2)\n         ğŸ” Testing variant: 'acounts'\n         ğŸ” Testing variant: 'ACOUNTS'\n         ğŸ” Testing variant: 'Acounts'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No list indicator found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No show indicator found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'lidt' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'acounts' classified as unknown\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No show indicator found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No list indicator found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['lidt', 'all', 'acounts']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\n   ğŸ“Š Segments detected: [['lidt', 'all', 'acounts']]\n\n   ğŸ¯ Processing English segment 1: ['lidt', 'all', 'acounts']\n      ğŸ” Analyzing English segment: ['lidt', 'all', 'acounts']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   â“ ENGLISH PATTERN: UNKNOWN\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['lidt', 'all', 'acounts']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'lidt all acounts'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: unknown\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: lidt, acounts']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: lidt, acounts']}",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-12-14T03:45:57.340283",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: list all acounts",
    "session_time": 3524.5668
  },
  {
    "timestamp": "2025-12-14T03:45:57.340321",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 3524.566838
  },
  {
    "timestamp": "2025-12-14T03:45:57.340362",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 3524.566879
  },
  {
    "timestamp": "2025-12-14T03:45:57.340372",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 3524.566889
  },
  {
    "timestamp": "2025-12-14T03:45:57.340379",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'list all acounts'",
    "session_time": 3524.566896
  },
  {
    "timestamp": "2025-12-14T03:45:57.340385",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 3524.566902
  },
  {
    "timestamp": "2025-12-14T03:45:57.340403",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 3524.56692
  },
  {
    "timestamp": "2025-12-14T03:45:57.344534",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251214_024712",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251214_024712",
      "timestamp": "2025-12-14T03:45:57.344492",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all acounts'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all acounts'\nğŸ” DEBUG: Query con placeholders: 'list all acounts'\nğŸ” DEBUG: Text en minÃºsculas: 'list all acounts'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all acounts'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all acounts'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all acounts'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all acounts'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'acounts']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'acounts']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all acounts'\nğŸ”§ Normalizing English query: 'list all acounts'\nâœ… English normalized: 'list all acounts'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'acounts']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'acounts']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'acounts' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'acounts']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'acounts']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'acounts']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'acounts'] (positions 0-2)\n         ğŸ” Testing variant: 'list all acounts'\n         ğŸ” Testing variant: 'LIST ALL ACOUNTS'\n         ğŸ” Testing variant: 'listallacounts'\n         ğŸ” Testing variant: 'list(all(acounts'\n         ğŸ” Testing variant: 'LISTALLACOUNTS'\n         ğŸ” Testing variant: 'list_all_acounts'\n         ğŸ” Testing variant: 'LIST_ALL_ACOUNTS'\n         ğŸ” Testing variant: 'List All Acounts'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'acounts'] (positions 1-2)\n         ğŸ” Testing variant: 'all acounts'\n         ğŸ” Testing variant: 'ALL ACOUNTS'\n         ğŸ” Testing variant: 'allacounts'\n         ğŸ” Testing variant: 'all(acounts'\n         ğŸ” Testing variant: 'ALLACOUNTS'\n         ğŸ” Testing variant: 'all_acounts'\n         ğŸ” Testing variant: 'ALL_ACOUNTS'\n         ğŸ” Testing variant: 'All Acounts'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['acounts'] (positions 2-2)\n         ğŸ” Testing variant: 'acounts'\n         ğŸ” Testing variant: 'ACOUNTS'\n         ğŸ” Testing variant: 'Acounts'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'acounts']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'acounts' classified as unknown\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'acounts']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\n   ğŸ“Š Segments detected: [['list', 'all', 'acounts']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'acounts']\n      ğŸ” Analyzing English segment: ['list', 'all', 'acounts']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   â“ ENGLISH PATTERN: UNKNOWN\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'acounts']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all acounts'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: unknown\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: list, acounts']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: list, acounts']}",
      "stderr_content": "",
      "has_content": true
    }
  }
]