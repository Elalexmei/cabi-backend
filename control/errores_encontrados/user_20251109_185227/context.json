[
  {
    "timestamp": "2025-11-09T18:52:27.931299",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "tableanalyzer_init",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:27.931287",
      "operation_name": "tableanalyzer_init",
      "stdout_content": "ğŸ¯ INICIALIZANDO ANALIZADOR COMPATIBLE CON PALABRAS ANCLA\n======================================================================\nğŸ“ CARGANDO DICCIONARIOS CON PALABRAS ANCLA\nğŸ“‚ Ruta: /Users/apple/Desktop/chambiacion/proyectos_full/python/brandbot/etapas/cassian_0.0.5_etapa_5/diccionarios/complejos\n============================================================\nâœ… Estructura JSON de palabras ancla verificada\n   âœ… anchors/dimension_anchors.json\n   ğŸ”¥ Expandido: 19 anclas â†’ 532 dimensiones\n   âœ… anchors/metric_anchors.json\n   ğŸ”¥ Expandido: 20 anclas â†’ 490 mÃ©tricas\n   âœ… core/operations.json\n   âœ… core/known_columns.json\n   âœ… core/common_values.json\n   âš ï¸ No encontrado: linguistic/connectors.json\n   âš ï¸ No encontrado: linguistic/word_numbers.json\n   âš ï¸ No encontrado: linguistic/typo_corrections.json\n   âœ… temporal/temporal_indicators.json\n   âœ… temporal/temporal_units.json\n\nğŸ“Š RESULTADO DE CARGA CON PALABRAS ANCLA:\n   âœ… Archivos bÃ¡sicos cargados: 3/3\n   ğŸ“‚ Dimensiones (expandidas): 532\n   ğŸ“Š MÃ©tricas (expandidas): 490\n   âš¡ Operaciones: 57\n   ğŸ“ Anclas de dimensiÃ³n: 19\n   ğŸ“ Anclas de mÃ©trica: 20\n   ğŸ• Cargado: 2025-11-09 18:52:27\nâœ… Diccionarios con palabras ancla cargados exitosamente\nğŸ”¥ TODAS LAS VARIACIONES DISPONIBLES: 1022 tÃ©rminos\nâœ… Estructura JSON de palabras ancla verificada\nâœ… Diccionarios con palabras ancla cargados:\nğŸ“ Ruta: /Users/apple/Desktop/chambiacion/proyectos_full/python/brandbot/etapas/cassian_0.0.5_etapa_5/diccionarios/complejos\nğŸ• Ãšltima carga: 2025-11-09T18:52:27.886148\nâœ… Carga exitosa: True\nğŸ”¥ Sistema de anclas: True\nğŸ“Š EstadÃ­sticas cargadas:\n   ğŸ“‚ Dimensiones (expandidas): 532\n   ğŸ“Š MÃ©tricas (expandidas): 490\n   âš¡ Operaciones: 57\n   ğŸ“ Anclas de dimensiÃ³n: 19\n   ğŸ“ Anclas de mÃ©trica: 20\n\nğŸ”¥ EJEMPLO DE EXPANSIONES CARGADAS:\n   ğŸ“‚ 'employee': 48 variaciones â†’ ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal']...\n   ğŸ“‚ 'category': 34 variaciones â†’ ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat']...\nğŸ“ Directorios temporales verificados\nğŸ”¥ Analizador compatible con palabras ancla listo\nâœ… MySQL disponible: localhost/datos_imperiales\nğŸ”¥ Analizador con opciÃ³n MySQL listo\nâœ… ClickHouse disponible: localhost/datos_imperiales\nğŸ”¥ Analizador con opciones MySQL + ClickHouse listo",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:27.938207",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_init",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:27.938202",
      "operation_name": "problemizador_init",
      "stdout_content": "âœ… Operaciones cargadas: 161 palabras ancla\n   ğŸ‡ªğŸ‡¸ Aliases configurados para ESPAÃ‘OL\n   âœ… Conectores activos: 30 palabras\n   âœ… NÃºmeros activos: 31 palabras\n   âœ… Correcciones activas: 20 palabras\nâœ… Diccionario temporal cargado: 1078 entradas\nâœ… Diccionarios JSON cargados exitosamente\nğŸ”§ Construyendo Ã­ndices de bÃºsqueda optimizada...\nâœ… Ãndice temporal: 1078 entradas\nâœ… Frases compuestas en cache: 211 entradas\nâœ… Ãndices construidos: 1011 palabras en 0.001s\nğŸ“‹ Log de palabras desconocidas cargado: 3 consultas previas\nğŸš€ Parser NLP Unificado iniciado\nğŸ“š Diccionarios cargados: {'total_dimensiones': 392, 'total_operaciones': 161, 'total_metricas': 384, 'source': 'JSON files'}\nğŸš¨ Sistema de palabras desconocidas activado\nğŸ“ Log de palabras desconocidas: control/consultas_sin_respuestas/unknown_words_log.json",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:27.938779",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "sql_mapper_init",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:27.938770",
      "operation_name": "sql_mapper_init",
      "stdout_content": "âœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:36.912509",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:36.912483",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'List all Ã­tems'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'List all Ã­tems'\nğŸ” DEBUG: Query con placeholders: 'List all Ã­tems'\nğŸ” DEBUG: Text en minÃºsculas: 'list all Ã­tems'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all Ã­tems'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all Ã­tems'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all Ã­tems'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all Ã­tems'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'Ã­tems']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'Ã­tems']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'List all Ã­tems'\nğŸ”§ Normalizing English query: 'list all Ã­tems'\nâœ… English normalized: 'list all Ã­tems'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'Ã­tems']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'Ã­tems']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'Ã­tems' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'Ã­tems']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'Ã­tems'] (positions 0-2)\n         ğŸ” Testing variant: 'list all Ã­tems'\n         ğŸ” Testing variant: 'LIST ALL ÃTEMS'\n         ğŸ” Testing variant: 'listallÃ­tems'\n         ğŸ” Testing variant: 'list(all(Ã­tems'\n         ğŸ” Testing variant: 'LISTALLÃTEMS'\n         ğŸ” Testing variant: 'list_all_Ã­tems'\n         ğŸ” Testing variant: 'LIST_ALL_ÃTEMS'\n         ğŸ” Testing variant: 'List All Ãtems'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'Ã­tems'] (positions 1-2)\n         ğŸ” Testing variant: 'all Ã­tems'\n         ğŸ” Testing variant: 'ALL ÃTEMS'\n         ğŸ” Testing variant: 'allÃ­tems'\n         ğŸ” Testing variant: 'all(Ã­tems'\n         ğŸ” Testing variant: 'ALLÃTEMS'\n         ğŸ” Testing variant: 'all_Ã­tems'\n         ğŸ” Testing variant: 'ALL_ÃTEMS'\n         ğŸ” Testing variant: 'All Ãtems'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['Ã­tems'] (positions 2-2)\n         ğŸ” Testing variant: 'Ã­tems'\n         ğŸ” Testing variant: 'ÃTEMS'\n         ğŸ” Testing variant: 'Ãtems'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'Ã­tems' classified as unknown\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'Ã­tems']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\n   ğŸ“Š Segments detected: [['list', 'all', 'Ã­tems']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'Ã­tems']\n      ğŸ” Analyzing English segment: ['list', 'all', 'Ã­tems']\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   â“ ENGLISH PATTERN: UNKNOWN\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'Ã­tems']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all Ã­tems'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: unknown\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: list, Ã­tems']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing main dimension; Missing metric, operation or condition', 'suggestions': ['Add an entity like: store, account, product, customer', 'Add a metric like: sales, revenue, inventory', 'English unrecognized words: list, Ã­tems']}",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:50.757785",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: List first 10 rows",
    "session_time": 23.007393
  },
  {
    "timestamp": "2025-11-09T18:52:50.757828",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 23.007436
  },
  {
    "timestamp": "2025-11-09T18:52:50.757868",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 23.007476
  },
  {
    "timestamp": "2025-11-09T18:52:50.757873",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 23.007481
  },
  {
    "timestamp": "2025-11-09T18:52:50.757878",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'List first 10 rows'",
    "session_time": 23.007486
  },
  {
    "timestamp": "2025-11-09T18:52:50.757884",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 23.007492
  },
  {
    "timestamp": "2025-11-09T18:52:50.757891",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 23.007499
  },
  {
    "timestamp": "2025-11-09T18:52:50.767756",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:50.767702",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'List first 10 rows'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'List first 10 rows'\nğŸ” DEBUG: Query con placeholders: 'List first 10 rows'\nğŸ” DEBUG: Text en minÃºsculas: 'list first 10 rows'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list first 10 rows'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list first 10 rows'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list first 10 rows'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list first 10 rows'\nğŸ” TOKENS ORIGINALES: ['list', 'first', '10', 'rows']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'first', '10', 'rows']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'rows' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'List first 10 rows'\nğŸ”§ Normalizing English query: 'list first 10 rows'\nâœ… English normalized: 'list first 10 rows'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'first', '10', 'rows']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'first', '10', 'rows']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'rows' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'first', '10', 'rows']\n   ğŸ“ Total tokens: 4\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'first', '10', 'rows']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'first', '10', 'rows']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'first', '10', 'rows'] (positions 0-3)\n         ğŸ” Testing variant: 'list first 10 rows'\n         ğŸ” Testing variant: 'LIST FIRST 10 ROWS'\n         ğŸ” Testing variant: 'listfirst10rows'\n         ğŸ” Testing variant: 'list(first(10(rows'\n         ğŸ” Testing variant: 'LISTFIRST10ROWS'\n         ğŸ” Testing variant: 'list_first_10_rows'\n         ğŸ” Testing variant: 'LIST_FIRST_10_ROWS'\n         ğŸ” Testing variant: 'List First 10 Rows'\n      ğŸ” Testing combination: ['list', 'first', '10'] (positions 0-2)\n         ğŸ” Testing variant: 'list first 10'\n         ğŸ” Testing variant: 'LIST FIRST 10'\n         ğŸ” Testing variant: 'listfirst10'\n         ğŸ” Testing variant: 'list(first(10'\n         ğŸ” Testing variant: 'LISTFIRST10'\n         ğŸ” Testing variant: 'list_first_10'\n         ğŸ” Testing variant: 'LIST_FIRST_10'\n         ğŸ” Testing variant: 'List First 10'\n      ğŸ” Testing combination: ['list', 'first'] (positions 0-1)\n         ğŸ” Testing variant: 'list first'\n         ğŸ” Testing variant: 'LIST FIRST'\n         ğŸ” Testing variant: 'listfirst'\n         ğŸ” Testing variant: 'list(first'\n         ğŸ” Testing variant: 'LISTFIRST'\n         ğŸ” Testing variant: 'list_first'\n         ğŸ” Testing variant: 'LIST_FIRST'\n         ğŸ” Testing variant: 'List First'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['first', '10', 'rows'] (positions 1-3)\n         ğŸ” Testing variant: 'first 10 rows'\n         ğŸ” Testing variant: 'FIRST 10 ROWS'\n         ğŸ” Testing variant: 'first10rows'\n         ğŸ” Testing variant: 'first(10(rows'\n         ğŸ” Testing variant: 'FIRST10ROWS'\n         ğŸ” Testing variant: 'first_10_rows'\n         ğŸ” Testing variant: 'FIRST_10_ROWS'\n         ğŸ” Testing variant: 'First 10 Rows'\n      ğŸ” Testing combination: ['first', '10'] (positions 1-2)\n         ğŸ” Testing variant: 'first 10'\n         ğŸ” Testing variant: 'FIRST 10'\n         ğŸ” Testing variant: 'first10'\n         ğŸ” Testing variant: 'first(10'\n         ğŸ” Testing variant: 'FIRST10'\n         ğŸ” Testing variant: 'first_10'\n         ğŸ” Testing variant: 'FIRST_10'\n         ğŸ” Testing variant: 'First 10'\n      ğŸ” Testing combination: ['first'] (positions 1-1)\n         ğŸ” Testing variant: 'first'\n         ğŸ” Testing variant: 'FIRST'\n         ğŸ” Testing variant: 'First'\n      ğŸ” Testing combination: ['10', 'rows'] (positions 2-3)\n         ğŸ” Testing variant: '10 rows'\n         ğŸ” Testing variant: '10 ROWS'\n         ğŸ” Testing variant: '10rows'\n         ğŸ” Testing variant: '10(rows'\n         ğŸ” Testing variant: '10ROWS'\n         ğŸ” Testing variant: '10_rows'\n         ğŸ” Testing variant: '10_ROWS'\n         ğŸ” Testing variant: '10 Rows'\n      ğŸ” Testing combination: ['10'] (positions 2-2)\n         ğŸ” Testing variant: '10'\n      ğŸ” Testing combination: ['rows'] (positions 3-3)\n         ğŸ” Testing variant: 'rows'\n         ğŸ” Testing variant: 'ROWS'\n         ğŸ” Testing variant: 'Rows'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'first', '10', 'rows']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'first', '10', 'rows']\n   âœ… List indicator: 'list' at position 0\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'first', '10', 'rows']\n   âœ… Show indicator: 'list' at position 0\n   âœ… Position indicator: 'first' at position 1\n   âœ… Row count (number): 10\n   âœ… Object type: 'rows'\nğŸ“Š SHOW ROWS PATTERN DETECTED:\n   ğŸ“Š Show indicator: list\n   ğŸ“ Position: first\n   ğŸ”¢ Row count: 10\n   ğŸ“‹ Object type: rows\n   â­ Confidence: 1.00\nğŸ“Š DEBUG: show_rows_pattern = True\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'first' classified as operation\nğŸ” English token '10' classified as value\nğŸ” English token 'rows' classified as connector\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'first', '10', 'rows']\n   âœ… Show indicator: 'list' at position 0\n   âœ… Position indicator: 'first' at position 1\n   âœ… Row count (number): 10\n   âœ… Object type: 'rows'\nğŸ“Š SHOW ROWS PATTERN DETECTED:\n   ğŸ“Š Show indicator: list\n   ğŸ“ Position: first\n   ğŸ”¢ Row count: 10\n   ğŸ“‹ Object type: rows\n   â­ Confidence: 1.00\n   ğŸ“Š Show rows pattern detected: True\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'first', '10', 'rows']\n   âœ… List indicator: 'list' at position 0\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'first', '10', 'rows']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'first', '10', 'rows']\n   ğŸ“Š Segments detected: [['list', 'first', '10', 'rows']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'first', '10', 'rows']\n      ğŸ” Analyzing English segment: ['list', 'first', '10', 'rows']\n         âš¡ English operation found: first\n         âŒ English criteria incomplete:\n             Operation: first\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   âš¡ English operation: first\n   ğŸ“Š Structure marked as SHOW_ROWS (overriding ranking)\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['first']\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“Š ENGLISH PATTERN: SHOW_ROWS (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list first 10 rows'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: show_rows\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: True\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ“Š SHOW_ROWS pattern detected - using special validation\n   âœ… SHOW_ROWS validation passed - count: 10\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = False\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“Š DETECTED: English show rows â†’ using specialized generator\nğŸ“Š GENERATING SHOW ROWS SQL:\n   ğŸ“Š Show type: list\n   ğŸ“ Position: first\n   ğŸ”¢ Count: 10\n   ğŸ“‹ Object: rows\n   ğŸ”„ Using ascending order for 'first' rows\n   ğŸ¯ Show rows SQL: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;\n      ğŸ” Searching for 'ROWID' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Product_Group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'item_group' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'partner_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'customer_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'vendor_code' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'location' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Dead_Inventory' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Channel' (data type: <class 'list'>)\n      ğŸ“Š Checking metric_anchors (type: <class 'dict'>)\n         ğŸ” Checking metric anchor_key: 'Sell_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Stock_Out' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sell_through' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'sales_amount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'order_number' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'profit' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'margin' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'quantity' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Inventory' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'price' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'cost' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'orders' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'transactions' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_8w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Avg_4w' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Week' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'roi' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'discount' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'revenue' (data type: <class 'list'>)\n         ğŸ” Checking metric anchor_key: 'Venta_perdida' (data type: <class 'list'>)\n      âŒ No mapping found for 'ROWID'\n      ğŸ” DEBUG - Sample dimension_anchors structure:\n         'employee': <class 'list'> = ['vendedor', 'vendedores', 'empleado', 'empleados', 'personal', 'staff', 'agente', 'agentes', 'representante', 'representantes', 'ejecutivo', 'ejecutivos', 'asesor', 'asesores', 'colaborador', 'colaboradores', 'trabajador', 'trabajadores', 'operador', 'operadores', 'consultor', 'consultores', 'employee', 'employees', 'worker', 'workers', 'staff', 'personnel', 'agent', 'agents', 'representative', 'representatives', 'executive', 'executives', 'advisor', 'advisors', 'consultant', 'consultants', 'operator', 'operators', 'associate', 'associates', 'team_member', 'team_members', 'crew', 'workforce', 'human_resource', 'human_resources']\n         'category': <class 'list'> = ['categoria', 'categorias', 'categorÃ­a', 'categorÃ­as', 'cat', 'cats', 'clasificacion', 'clasificaciones', 'clasificaciÃ³n', 'segmento', 'segmentos', 'division', 'divisiones', 'divisiÃ³n', 'category', 'categories', 'classification', 'classifications', 'segment', 'segments', 'division', 'divisions', 'group', 'groups', 'type', 'types', 'kind', 'kinds', 'class', 'classes', 'section', 'sections', 'grouping', 'groupings']\n         'brand': <class 'list'> = ['marca', 'marcas', 'brand', 'brands', 'etiqueta', 'etiquetas', 'label', 'labels', 'fabricante', 'fabricantes', 'proveedor_marca', 'casa', 'casas', 'firma', 'firmas', 'nombre_comercial', 'manufacturer', 'manufacturers', 'maker', 'makers', 'producer', 'producers', 'supplier', 'suppliers', 'vendor', 'vendors', 'company', 'companies', 'trademark', 'trademarks', 'brandname', 'brandnames', 'marque', 'logo']\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n   ğŸ“¤ Output: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;\n   ğŸ“Š Reemplazos realizados: 0\n   ğŸ“¤ Output: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;\n   ğŸ“Š Reemplazos realizados: 0\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:50.767773",
    "component": "nlp",
    "level": "info",
    "message": "âœ… Problemizador completado:",
    "session_time": 23.017381
  },
  {
    "timestamp": "2025-11-09T18:52:50.767785",
    "component": "nlp",
    "level": "info",
    "message": "   ğŸ—„ï¸ SQL conceptual generado: SELECT * FROM datos ORDER BY ROWID ASC LIMIT 10;",
    "session_time": 23.017393
  },
  {
    "timestamp": "2025-11-09T18:52:50.767844",
    "component": "nlp",
    "level": "info",
    "message": "âœ… SUCCESS: Procesando consulta (9ms)",
    "session_time": 23.017452
  },
  {
    "timestamp": "2025-11-09T18:52:50.767863",
    "component": "exec",
    "level": "info",
    "message": "ğŸ—„ï¸ EJECUTANDO SQL - MODO: clickhouse",
    "session_time": 23.017471
  },
  {
    "timestamp": "2025-11-09T18:52:50.767869",
    "component": "exec",
    "level": "info",
    "message": "   ğŸš€ Destino: ClickHouse (Motor Columnar)",
    "session_time": 23.017477
  },
  {
    "timestamp": "2025-11-09T18:52:50.767879",
    "component": "exec",
    "level": "info",
    "message": "ğŸš€ PASO 3: EJECUCIÃ“N EN CLICKHOUSE",
    "session_time": 23.017487
  },
  {
    "timestamp": "2025-11-09T18:52:50.993880",
    "component": "clickhouse",
    "level": "exception_details",
    "error_details": {
      "exception_type": "DatabaseError",
      "exception_message": "Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ROWID` in scope SELECT * FROM datos_output_data_3_20251109_175144_f41774 ORDER BY ROWID ASC LIMIT 10. (UNKNOWN_IDENTIFIER) (version 25.10.1.3832 (official build)) (for url http://localhost:8123)",
      "context": "Error ejecutando query ClickHouse",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/apple/Desktop/chambiacion/proyectos_full/python/brandbot/etapas/cassian_0.0.5_etapa_5/interfaz/../ejecutor.py\", line 1782, in _execute_sql_on_clickhouse\n    result = self.clickhouse_manager.client.query(final_query)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clickhouse_connect/driver/client.py\", line 238, in query\n    return self._query_with_context(query_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 286, in _query_with_context\n    response = self._raw_request(body,\n               ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 546, in _raw_request\n    self._error_handler(response)\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 467, in _error_handler\n    raise OperationalError(err_str) if retried else DatabaseError(err_str) from None\nclickhouse_connect.driver.exceptions.DatabaseError: Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ROWID` in scope SELECT * FROM datos_output_data_3_20251109_175144_f41774 ORDER BY ROWID ASC LIMIT 10. (UNKNOWN_IDENTIFIER) (version 25.10.1.3832 (official build)) (for url http://localhost:8123)\n"
    }
  },
  {
    "timestamp": "2025-11-09T18:52:58.868161",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: List all accounts",
    "session_time": 31.117769
  },
  {
    "timestamp": "2025-11-09T18:52:58.868232",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 31.11784
  },
  {
    "timestamp": "2025-11-09T18:52:58.868276",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 31.117884
  },
  {
    "timestamp": "2025-11-09T18:52:58.868282",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 31.11789
  },
  {
    "timestamp": "2025-11-09T18:52:58.868288",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'List all accounts'",
    "session_time": 31.117896
  },
  {
    "timestamp": "2025-11-09T18:52:58.868293",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 31.117901
  },
  {
    "timestamp": "2025-11-09T18:52:58.868303",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 31.117911
  },
  {
    "timestamp": "2025-11-09T18:52:58.879412",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:52:58.878244",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'List all accounts'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'List all accounts'\nğŸ” DEBUG: Query con placeholders: 'List all accounts'\nğŸ” DEBUG: Text en minÃºsculas: 'list all accounts'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all accounts'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all accounts'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all accounts'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all accounts'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'accounts']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'accounts']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'List all accounts'\nğŸ”§ Normalizing English query: 'list all accounts'\nâœ… English normalized: 'list all accounts'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'accounts']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'accounts']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'accounts' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'accounts']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'accounts']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'accounts']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'accounts'] (positions 0-2)\n         ğŸ” Testing variant: 'list all accounts'\n         ğŸ” Testing variant: 'LIST ALL ACCOUNTS'\n         ğŸ” Testing variant: 'listallaccounts'\n         ğŸ” Testing variant: 'list(all(accounts'\n         ğŸ” Testing variant: 'LISTALLACCOUNTS'\n         ğŸ” Testing variant: 'list_all_accounts'\n         ğŸ” Testing variant: 'LIST_ALL_ACCOUNTS'\n         ğŸ” Testing variant: 'List All Accounts'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'accounts'] (positions 1-2)\n         ğŸ” Testing variant: 'all accounts'\n         ğŸ” Testing variant: 'ALL ACCOUNTS'\n         ğŸ” Testing variant: 'allaccounts'\n         ğŸ” Testing variant: 'all(accounts'\n         ğŸ” Testing variant: 'ALLACCOUNTS'\n         ğŸ” Testing variant: 'all_accounts'\n         ğŸ” Testing variant: 'ALL_ACCOUNTS'\n         ğŸ” Testing variant: 'All Accounts'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['accounts'] (positions 2-2)\n         ğŸ” Testing variant: 'accounts'\n         ğŸ” Testing variant: 'ACCOUNTS'\n         ğŸ” Testing variant: 'Accounts'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'accounts']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'accounts']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'accounts'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: accounts\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\nğŸ“‹ DEBUG: list_all_pattern = True\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'accounts']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'accounts' classified as dimension\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'accounts']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'accounts']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'accounts'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: accounts\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\n   ğŸ“‹ List all pattern detected: True\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'accounts']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'accounts')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'accounts']\n   ğŸ“Š Segments detected: [['list', 'all', 'accounts']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'accounts']\n      ğŸ” Analyzing English segment: ['list', 'all', 'accounts']\n         ğŸ“ English dimension candidate: accounts\n         ğŸ”„ English dimension converted to metric: accounts\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: accounts\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: accounts\n   ğŸ“‹ Structure marked as LIST_ALL\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: accounts\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all accounts'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: True\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: True\n   ğŸ“‹ LIST_ALL pattern detected - using special validation\n   âœ… LIST_ALL validation passed - target: accounts\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = True\nğŸ”§ DEBUG: list_all_pattern value = {'pattern_type': 'LIST_ALL', 'list_indicator': 'list', 'has_all_indicator': True, 'all_indicator': 'all', 'target_dimension': 'accounts', 'has_aggregation': False, 'confidence': 0.9999999999999999, 'raw_tokens': ['list', 'all', 'accounts'], 'is_temporal_list': False}\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“‹ DETECTED: Enhanced English list all â†’ using ENHANCED specialized generator\nğŸ“‹ GENERATING ENHANCED LIST ALL SQL (WITH DISTINCT/GROUP BY LOGIC):\n   ğŸ“‹ List type: list\n   ğŸ“ Target dimension: accounts\n   ğŸ“Š Has aggregation: False\n   ğŸ“‹ Simple list - using DISTINCT\n   âœ… Using DISTINCT for unique values\n   â° Processing temporal conditions for LIST ALL...\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   â° Found 0 temporal conditions\n   ğŸ¯ Enhanced LIST ALL SQL: SELECT DISTINCT accounts FROM datos ORDER BY accounts;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT DISTINCT accounts FROM datos ORDER BY accounts;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT DISTINCT accounts FROM datos ORDER BY accounts;\n      ğŸ” Searching for 'accounts' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n      âœ… Dimension match: 'accounts' â†’ 'Account' (list structure)\n   ğŸ”„ Standalone mapping: 'accounts' â†’ Account\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT DISTINCT Account FROM datos ORDER BY Account;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 44\n      ğŸ“ Added quotes: Account â†’ \"Account\" at position 16\n   ğŸ“¤ Output: SELECT DISTINCT \"Account\" FROM datos ORDER BY \"Account\";\n   ğŸ“Š Reemplazos realizados: 2\n   ğŸ“¤ Output: SELECT DISTINCT \"Account\" FROM datos ORDER BY \"Account\";\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT DISTINCT \"Account\" FROM datos ORDER BY \"Account\";'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: accounts\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Parte principal: (accounts)\n   ğŸ¯ Resultado final COMPUESTO: (accounts)\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT DISTINCT \"Account\" FROM datos ORDER BY \"Account\";'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:52:58.879456",
    "component": "nlp",
    "level": "info",
    "message": "âœ… Problemizador completado:",
    "session_time": 31.129064
  },
  {
    "timestamp": "2025-11-09T18:52:58.879479",
    "component": "nlp",
    "level": "info",
    "message": "   ğŸ—„ï¸ SQL conceptual generado: SELECT DISTINCT \"Account\" FROM datos ORDER BY \"Account\";",
    "session_time": 31.129087
  },
  {
    "timestamp": "2025-11-09T18:52:58.879564",
    "component": "nlp",
    "level": "info",
    "message": "âœ… SUCCESS: Procesando consulta (11ms)",
    "session_time": 31.129172
  },
  {
    "timestamp": "2025-11-09T18:52:58.879591",
    "component": "exec",
    "level": "info",
    "message": "ğŸ—„ï¸ EJECUTANDO SQL - MODO: clickhouse",
    "session_time": 31.129199
  },
  {
    "timestamp": "2025-11-09T18:52:58.879601",
    "component": "exec",
    "level": "info",
    "message": "   ğŸš€ Destino: ClickHouse (Motor Columnar)",
    "session_time": 31.129209
  },
  {
    "timestamp": "2025-11-09T18:52:58.879615",
    "component": "exec",
    "level": "info",
    "message": "ğŸš€ PASO 3: EJECUCIÃ“N EN CLICKHOUSE",
    "session_time": 31.129223
  },
  {
    "timestamp": "2025-11-09T18:52:58.987418",
    "component": "exec",
    "level": "info",
    "message": "âœ… Query ejecutada: 75 filas en 107ms",
    "session_time": 31.237026
  },
  {
    "timestamp": "2025-11-09T18:52:58.988448",
    "component": "flask",
    "level": "info",
    "message": "âœ… Consulta Flask exitosa: 75 filas",
    "session_time": 31.238056
  },
  {
    "timestamp": "2025-11-09T18:53:35.858757",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: list all item",
    "session_time": 68.108365
  },
  {
    "timestamp": "2025-11-09T18:53:35.858992",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 68.1086
  },
  {
    "timestamp": "2025-11-09T18:53:35.859424",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 68.109032
  },
  {
    "timestamp": "2025-11-09T18:53:35.859434",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 68.109042
  },
  {
    "timestamp": "2025-11-09T18:53:35.859450",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'list all item'",
    "session_time": 68.109058
  },
  {
    "timestamp": "2025-11-09T18:53:35.859457",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 68.109065
  },
  {
    "timestamp": "2025-11-09T18:53:35.859478",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 68.109086
  },
  {
    "timestamp": "2025-11-09T18:53:35.872933",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:53:35.872854",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all item'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all item'\nğŸ” DEBUG: Query con placeholders: 'list all item'\nğŸ” DEBUG: Text en minÃºsculas: 'list all item'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all item'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all item'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all item'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all item'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'item']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'item']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all item'\nğŸ”§ Normalizing English query: 'list all item'\nâœ… English normalized: 'list all item'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'item']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'item']\nğŸ§  English semantic intent: DEFAULT\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'item']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'item']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'item']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'item'] (positions 0-2)\n         ğŸ” Testing variant: 'list all item'\n         ğŸ” Testing variant: 'LIST ALL ITEM'\n         ğŸ” Testing variant: 'listallitem'\n         ğŸ” Testing variant: 'list(all(item'\n         ğŸ” Testing variant: 'LISTALLITEM'\n         ğŸ” Testing variant: 'list_all_item'\n         ğŸ” Testing variant: 'LIST_ALL_ITEM'\n         ğŸ” Testing variant: 'List All Item'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'item'] (positions 1-2)\n         ğŸ” Testing variant: 'all item'\n         ğŸ” Testing variant: 'ALL ITEM'\n         ğŸ” Testing variant: 'allitem'\n         ğŸ” Testing variant: 'all(item'\n         ğŸ” Testing variant: 'ALLITEM'\n         ğŸ” Testing variant: 'all_item'\n         ğŸ” Testing variant: 'ALL_ITEM'\n         ğŸ” Testing variant: 'All Item'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['item'] (positions 2-2)\n         ğŸ” Testing variant: 'item'\n         ğŸ” Testing variant: 'ITEM'\n         ğŸ” Testing variant: 'Item'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'item']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'item']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'item'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: item\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\nğŸ“‹ DEBUG: list_all_pattern = True\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'item']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'item' classified as dimension\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'item']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'item']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'item'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: item\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\n   ğŸ“‹ List all pattern detected: True\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'item']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'item')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'item']\n   ğŸ“Š Segments detected: [['list', 'all', 'item']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'item']\n      ğŸ” Analyzing English segment: ['list', 'all', 'item']\n         ğŸ“ English dimension candidate: item\n         ğŸ”„ English dimension converted to metric: item\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: item\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: item\n   ğŸ“‹ Structure marked as LIST_ALL\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: item\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all item'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: True\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: True\n   ğŸ“‹ LIST_ALL pattern detected - using special validation\n   âœ… LIST_ALL validation passed - target: item\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = True\nğŸ”§ DEBUG: list_all_pattern value = {'pattern_type': 'LIST_ALL', 'list_indicator': 'list', 'has_all_indicator': True, 'all_indicator': 'all', 'target_dimension': 'item', 'has_aggregation': False, 'confidence': 0.9999999999999999, 'raw_tokens': ['list', 'all', 'item'], 'is_temporal_list': False}\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“‹ DETECTED: Enhanced English list all â†’ using ENHANCED specialized generator\nğŸ“‹ GENERATING ENHANCED LIST ALL SQL (WITH DISTINCT/GROUP BY LOGIC):\n   ğŸ“‹ List type: list\n   ğŸ“ Target dimension: item\n   ğŸ“Š Has aggregation: False\n   ğŸ“‹ Simple list - using DISTINCT\n   âœ… Using DISTINCT for unique values\n   â° Processing temporal conditions for LIST ALL...\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   â° Found 0 temporal conditions\n   ğŸ¯ Enhanced LIST ALL SQL: SELECT DISTINCT item FROM datos ORDER BY item;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT DISTINCT item FROM datos ORDER BY item;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT DISTINCT item FROM datos ORDER BY item;\n      ğŸ” Searching for 'item' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n      âœ… Dimension match: 'item' â†’ 'Item' (list structure)\n   ğŸ”„ Standalone mapping: 'item' â†’ Item\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT DISTINCT Item FROM datos ORDER BY Item;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Item â†’ \"Item\" at position 41\n      ğŸ“ Added quotes: Item â†’ \"Item\" at position 16\n   ğŸ“¤ Output: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";\n   ğŸ“Š Reemplazos realizados: 2\n   ğŸ“¤ Output: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: item\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Parte principal: (item)\n   ğŸ¯ Resultado final COMPUESTO: (item)\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:53:35.872947",
    "component": "nlp",
    "level": "info",
    "message": "âœ… Problemizador completado:",
    "session_time": 68.122555
  },
  {
    "timestamp": "2025-11-09T18:53:35.872958",
    "component": "nlp",
    "level": "info",
    "message": "   ğŸ—„ï¸ SQL conceptual generado: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";",
    "session_time": 68.122566
  },
  {
    "timestamp": "2025-11-09T18:53:35.873040",
    "component": "nlp",
    "level": "info",
    "message": "âœ… SUCCESS: Procesando consulta (13ms)",
    "session_time": 68.122648
  },
  {
    "timestamp": "2025-11-09T18:53:35.873059",
    "component": "exec",
    "level": "info",
    "message": "ğŸ—„ï¸ EJECUTANDO SQL - MODO: clickhouse",
    "session_time": 68.122667
  },
  {
    "timestamp": "2025-11-09T18:53:35.873065",
    "component": "exec",
    "level": "info",
    "message": "   ğŸš€ Destino: ClickHouse (Motor Columnar)",
    "session_time": 68.122673
  },
  {
    "timestamp": "2025-11-09T18:53:35.873071",
    "component": "exec",
    "level": "info",
    "message": "ğŸš€ PASO 3: EJECUCIÃ“N EN CLICKHOUSE",
    "session_time": 68.122679
  },
  {
    "timestamp": "2025-11-09T18:53:36.032939",
    "component": "exec",
    "level": "info",
    "message": "âœ… Query ejecutada: 305 filas en 159ms",
    "session_time": 68.282547
  },
  {
    "timestamp": "2025-11-09T18:53:36.040474",
    "component": "flask",
    "level": "info",
    "message": "âœ… Consulta Flask exitosa: 305 filas",
    "session_time": 68.290082
  },
  {
    "timestamp": "2025-11-09T18:53:40.375074",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: list all items",
    "session_time": 72.624682
  },
  {
    "timestamp": "2025-11-09T18:53:40.375149",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 72.624757
  },
  {
    "timestamp": "2025-11-09T18:53:40.375196",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 72.624804
  },
  {
    "timestamp": "2025-11-09T18:53:40.375201",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 72.624809
  },
  {
    "timestamp": "2025-11-09T18:53:40.375207",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'list all items'",
    "session_time": 72.624815
  },
  {
    "timestamp": "2025-11-09T18:53:40.375212",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 72.62482
  },
  {
    "timestamp": "2025-11-09T18:53:40.375220",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 72.624828
  },
  {
    "timestamp": "2025-11-09T18:53:40.380319",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:53:40.380292",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all items'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all items'\nğŸ” DEBUG: Query con placeholders: 'list all items'\nğŸ” DEBUG: Text en minÃºsculas: 'list all items'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all items'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all items'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all items'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all items'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'items']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'items']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all items'\nğŸ”§ Normalizing English query: 'list all items'\nâœ… English normalized: 'list all items'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'items']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'items']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'items' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'items']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'items']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'items']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'items'] (positions 0-2)\n         ğŸ” Testing variant: 'list all items'\n         ğŸ” Testing variant: 'LIST ALL ITEMS'\n         ğŸ” Testing variant: 'listallitems'\n         ğŸ” Testing variant: 'list(all(items'\n         ğŸ” Testing variant: 'LISTALLITEMS'\n         ğŸ” Testing variant: 'list_all_items'\n         ğŸ” Testing variant: 'LIST_ALL_ITEMS'\n         ğŸ” Testing variant: 'List All Items'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'items'] (positions 1-2)\n         ğŸ” Testing variant: 'all items'\n         ğŸ” Testing variant: 'ALL ITEMS'\n         ğŸ” Testing variant: 'allitems'\n         ğŸ” Testing variant: 'all(items'\n         ğŸ” Testing variant: 'ALLITEMS'\n         ğŸ” Testing variant: 'all_items'\n         ğŸ” Testing variant: 'ALL_ITEMS'\n         ğŸ” Testing variant: 'All Items'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['items'] (positions 2-2)\n         ğŸ” Testing variant: 'items'\n         ğŸ” Testing variant: 'ITEMS'\n         ğŸ” Testing variant: 'Items'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'items']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'items']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'items'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: items\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\nğŸ“‹ DEBUG: list_all_pattern = True\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'items']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'items' classified as operation\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'items']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'items']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âœ… Target dimension: 'items'\nğŸ“‹ LIST ALL PATTERN DETECTED:\n   ğŸ“‹ List indicator: list\n   ğŸŒ Has 'all': True\n   ğŸ“ Target dimension: items\n   ğŸ“Š Has aggregation: False\n   â­ Confidence: 1.00\n   ğŸ“‹ List all pattern detected: True\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'items']\n   ğŸ• Temporal conditional pattern detected: False\n   ğŸ† Skipping ranking detection due to special patterns\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: []\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'items']\n   ğŸ“Š Segments detected: [['list', 'all', 'items']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'items']\n      ğŸ” Analyzing English segment: ['list', 'all', 'items']\n         âš¡ English operation found: items\n         âŒ English criteria incomplete:\n             Operation: items\n             Metric: NOT FOUND\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   âš¡ English operation: items\n   ğŸ“‹ Structure marked as LIST_ALL\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: N/A\n   ğŸ”— Multiple dimensions: 0\n   âš¡ Operations: ['items']\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL (special pattern priority)\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all items'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 1\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: True\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: True\n   ğŸ“‹ LIST_ALL pattern detected - using special validation\n   âœ… LIST_ALL validation passed - target: items\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': True, 'error': None, 'suggestions': []}\nğŸ”§ DEBUG: Antes de generar SQL...\nğŸ”§ DEBUG: hasattr list_all_pattern = True\nğŸ”§ DEBUG: list_all_pattern value = {'pattern_type': 'LIST_ALL', 'list_indicator': 'list', 'has_all_indicator': True, 'all_indicator': 'all', 'target_dimension': 'items', 'has_aggregation': False, 'confidence': 0.9999999999999999, 'raw_tokens': ['list', 'all', 'items'], 'is_temporal_list': False}\nğŸ”§ GENERATING OPTIMIZED SQL (Enhanced with LIST ALL support):\nğŸ“‹ DETECTED: Enhanced English list all â†’ using ENHANCED specialized generator\nğŸ“‹ GENERATING ENHANCED LIST ALL SQL (WITH DISTINCT/GROUP BY LOGIC):\n   ğŸ“‹ List type: list\n   ğŸ“ Target dimension: items\n   ğŸ“Š Has aggregation: False\n   ğŸ“‹ Simple list - using DISTINCT\n   âœ… Using DISTINCT for unique values\n   â° Processing temporal conditions for LIST ALL...\nğŸ”§ DEBUG EXTREMO: MÃ©todo get_advanced_temporal_sql_conditions_english INICIADO\nğŸ”§ DEBUG EXTREMO: Inicializando sql_conditions = []\nâ° GENERATING ADVANCED TEMPORAL CONDITIONS (With Special Patterns):\nğŸ”§ DEBUG EXTREMO: Verificando structure.temporal_filters...\nğŸ”§ DEBUG EXTREMO: hasattr(structure, 'temporal_filters') = True\nğŸ”§ DEBUG EXTREMO: structure.temporal_filters = []\nğŸ”§ DEBUG EXTREMO: len(structure.temporal_filters) = 0\n   ğŸ“‹ Total temporal filters in structure: 0\n   âš ï¸  No advanced_temporal_info available\nğŸ”§ DEBUG EXTREMO: sql_conditions final = []\nâ° TOTAL TEMPORAL CONDITIONS: 0\n   âŒ NO CONDITIONS GENERATED!\nğŸ”§ DEBUG EXTREMO: Retornando sql_conditions = []\n   â° Found 0 temporal conditions\n   ğŸ¯ Enhanced LIST ALL SQL: SELECT DISTINCT items FROM datos ORDER BY items;\nğŸ”§ DEBUG: SQL conceptual generado = 'SELECT DISTINCT items FROM datos ORDER BY items;'\nğŸ”— NORMALIZANDO SQL (Enhanced - Robust):\n   ğŸ“¥ Input: SELECT DISTINCT items FROM datos ORDER BY items;\n      ğŸ” Searching for 'items' in anchors...\n      ğŸ“ Checking dimension_anchors (type: <class 'dict'>)\n         ğŸ” Checking anchor_key: 'employee' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'category' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'brand' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'line' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'city' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'country' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'state' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Store' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Account' (data type: <class 'list'>)\n         ğŸ” Checking anchor_key: 'Item' (data type: <class 'list'>)\n      âœ… Dimension match: 'items' â†’ 'Item' (list structure)\n   ğŸ”„ Standalone mapping: 'items' â†’ Item\nğŸ”§ AGREGANDO COMILLAS (Dynamic - Using Anchors):\n   ğŸ“¥ Input: SELECT DISTINCT Item FROM datos ORDER BY Item;\n   ğŸ“Š Normalized columns from anchors: ['Account', 'Avg_4W', 'Avg_8W', 'Brand', 'Category', 'Channel', 'City', 'Cost', 'Country', 'Customer_Code', 'Dead_Inventory', 'Discount', 'Employee', 'Inventory', 'Item', 'Item_Group', 'Line', 'Location', 'Margin', 'Order_Number', 'Orders', 'Partner_Code', 'Price', 'Product_Group', 'Profit', 'Quantity', 'Revenue', 'Roi', 'Sales_Amount', 'Sell_Out', 'Sell_Through', 'State', 'Stock_Out', 'Store', 'Transactions', 'Vendor_Code', 'Venta_Perdida', 'Week']\n      ğŸ“ Added quotes: Item â†’ \"Item\" at position 41\n      ğŸ“ Added quotes: Item â†’ \"Item\" at position 16\n   ğŸ“¤ Output: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";\n   ğŸ“Š Reemplazos realizados: 2\n   ğŸ“¤ Output: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";\n   ğŸ“Š Reemplazos realizados: 1\nâœ… Schema mapping applied successfully\nğŸ”§ DEBUG: SQL final = 'SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";'\nğŸ”§ DEBUG: Creating final result...\nğŸ”§ DEBUG: query_structure type: <class 'problemizador_18.QueryStructure'>\nğŸ”§ DEBUG: Has get_complexity_level: True\nğŸ” Generando estructura jerÃ¡rquica para consulta compuesta:\n   ğŸ“ DimensiÃ³n: N/A\n   ğŸ”— Es compuesta: False\n   ğŸ”— Criterios compuestos: 0\n   â° Columnas temporales: set()\n   ğŸ”„ Â¿DimensiÃ³n en filtros? False\n   âœ… Solo operaciÃ³n: (items)\n   ğŸ¯ Resultado final COMPUESTO: (items)\nğŸ”§ DEBUG: Final result created successfully\nğŸ”§ DEBUG: SQL in result = 'SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";'",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:53:40.380336",
    "component": "nlp",
    "level": "info",
    "message": "âœ… Problemizador completado:",
    "session_time": 72.629944
  },
  {
    "timestamp": "2025-11-09T18:53:40.380347",
    "component": "nlp",
    "level": "info",
    "message": "   ğŸ—„ï¸ SQL conceptual generado: SELECT DISTINCT \"Item\" FROM datos ORDER BY \"Item\";",
    "session_time": 72.629955
  },
  {
    "timestamp": "2025-11-09T18:53:40.380415",
    "component": "nlp",
    "level": "info",
    "message": "âœ… SUCCESS: Procesando consulta (5ms)",
    "session_time": 72.630023
  },
  {
    "timestamp": "2025-11-09T18:53:40.380433",
    "component": "exec",
    "level": "info",
    "message": "ğŸ—„ï¸ EJECUTANDO SQL - MODO: clickhouse",
    "session_time": 72.630041
  },
  {
    "timestamp": "2025-11-09T18:53:40.380439",
    "component": "exec",
    "level": "info",
    "message": "   ğŸš€ Destino: ClickHouse (Motor Columnar)",
    "session_time": 72.630047
  },
  {
    "timestamp": "2025-11-09T18:53:40.380447",
    "component": "exec",
    "level": "info",
    "message": "ğŸš€ PASO 3: EJECUCIÃ“N EN CLICKHOUSE",
    "session_time": 72.630055
  },
  {
    "timestamp": "2025-11-09T18:53:40.508135",
    "component": "exec",
    "level": "info",
    "message": "âœ… Query ejecutada: 305 filas en 127ms",
    "session_time": 72.757743
  },
  {
    "timestamp": "2025-11-09T18:53:40.511505",
    "component": "flask",
    "level": "info",
    "message": "âœ… Consulta Flask exitosa: 305 filas",
    "session_time": 72.761113
  },
  {
    "timestamp": "2025-11-09T18:53:58.009208",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: list all weeks",
    "session_time": 90.258816
  },
  {
    "timestamp": "2025-11-09T18:53:58.009413",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 90.259021
  },
  {
    "timestamp": "2025-11-09T18:53:58.009505",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 90.259113
  },
  {
    "timestamp": "2025-11-09T18:53:58.009515",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 90.259123
  },
  {
    "timestamp": "2025-11-09T18:53:58.009528",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'list all weeks'",
    "session_time": 90.259136
  },
  {
    "timestamp": "2025-11-09T18:53:58.009533",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 90.259141
  },
  {
    "timestamp": "2025-11-09T18:53:58.009552",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 90.25916
  },
  {
    "timestamp": "2025-11-09T18:53:58.013549",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:53:58.013517",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'list all weeks'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'list all weeks'\nğŸ” DEBUG: Query con placeholders: 'list all weeks'\nğŸ” DEBUG: Text en minÃºsculas: 'list all weeks'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all weeks'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all weeks'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all weeks'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all weeks'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'weeks']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'weeks']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'list all weeks'\nğŸ”§ Normalizing English query: 'list all weeks'\nâœ… English normalized: 'list all weeks'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'weeks']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'weeks']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'weeks' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'weeks']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'weeks'] (positions 0-2)\n         ğŸ” Testing variant: 'list all weeks'\n         ğŸ” Testing variant: 'LIST ALL WEEKS'\n         ğŸ” Testing variant: 'listallweeks'\n         ğŸ” Testing variant: 'list(all(weeks'\n         ğŸ” Testing variant: 'LISTALLWEEKS'\n         ğŸ” Testing variant: 'list_all_weeks'\n         ğŸ” Testing variant: 'LIST_ALL_WEEKS'\n         ğŸ” Testing variant: 'List All Weeks'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'weeks'] (positions 1-2)\n         ğŸ” Testing variant: 'all weeks'\n         ğŸ” Testing variant: 'ALL WEEKS'\n         ğŸ” Testing variant: 'allweeks'\n         ğŸ” Testing variant: 'all(weeks'\n         ğŸ” Testing variant: 'ALLWEEKS'\n         ğŸ” Testing variant: 'all_weeks'\n         ğŸ” Testing variant: 'ALL_WEEKS'\n         ğŸ” Testing variant: 'All Weeks'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['weeks'] (positions 2-2)\n         ğŸ” Testing variant: 'weeks'\n         ğŸ” Testing variant: 'WEEKS'\n         ğŸ” Testing variant: 'Weeks'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'weeks' classified as dimension\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'weeks')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   ğŸ“Š Segments detected: [['list', 'all', 'weeks']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'weeks']\n      ğŸ” Analyzing English segment: ['list', 'all', 'weeks']\n         ğŸ“ English dimension candidate: weeks\n         ğŸ”„ English dimension converted to metric: weeks\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: weeks\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: weeks\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: weeks\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all weeks'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing metric, operation or condition', 'suggestions': ['Add a metric like: sales, revenue, inventory', 'English unrecognized words: list']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing metric, operation or condition', 'suggestions': ['Add a metric like: sales, revenue, inventory', 'English unrecognized words: list']}",
      "stderr_content": "",
      "has_content": true
    }
  },
  {
    "timestamp": "2025-11-09T18:54:04.066354",
    "component": "flask",
    "level": "info",
    "message": "ğŸ¯ Consulta Flask: List all weeks",
    "session_time": 96.315962
  },
  {
    "timestamp": "2025-11-09T18:54:04.066386",
    "component": "main",
    "level": "info",
    "message": "ğŸš€ INICIANDO FLUJO MAESTRO COMPLETO - MODO: clickhouse",
    "session_time": 96.315994
  },
  {
    "timestamp": "2025-11-09T18:54:04.066433",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ”„ INICIANDO: Procesando consulta",
    "session_time": 96.316041
  },
  {
    "timestamp": "2025-11-09T18:54:04.066436",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ§  PASO 2 MAESTRO: PROCESAMIENTO CON PROBLEMIZADOR",
    "session_time": 96.316044
  },
  {
    "timestamp": "2025-11-09T18:54:04.066440",
    "component": "nlp",
    "level": "info",
    "message": "â“ Consulta: 'List all weeks'",
    "session_time": 96.316048
  },
  {
    "timestamp": "2025-11-09T18:54:04.066443",
    "component": "nlp",
    "level": "info",
    "message": "ğŸ¯ Modo actual: clickhouse",
    "session_time": 96.316051
  },
  {
    "timestamp": "2025-11-09T18:54:04.066446",
    "component": "nlp",
    "level": "info",
    "message": "â”œâ”€â”€ Analizando lenguaje natural...",
    "session_time": 96.316054
  },
  {
    "timestamp": "2025-11-09T18:54:04.068438",
    "component": "suppressed_output",
    "level": "suppressed_component",
    "session_id": "user_20251109_185227",
    "operation": "problemizador_process",
    "suppressed_data": {
      "session_id": "user_20251109_185227",
      "timestamp": "2025-11-09T18:54:04.068414",
      "operation_name": "problemizador_process",
      "stdout_content": "ğŸ” ANALIZANDO CONSULTA: 'List all weeks'\nğŸ” DETECTANDO FRASES COMPUESTAS (Dictionary-Based): 'List all weeks'\nğŸ” DEBUG: Query con placeholders: 'List all weeks'\nğŸ” DEBUG: Text en minÃºsculas: 'list all weeks'\n   ğŸ” Generadas 211 frases compuestas automÃ¡ticamente\nğŸ” DEBUG: Antes de restaurar mayÃºsculas: 'list all weeks'\nğŸ”“ RESTAURANDO TOKENS:\n   ğŸ“¥ Input: 'list all weeks'\n   ğŸ”‘ Tokens preservados: {}\n   ğŸ“¤ Output: 'list all weeks'\nğŸ” DEBUG: DespuÃ©s de restaurar mayÃºsculas: 'list all weeks'\nğŸ” TOKENS ORIGINALES: ['list', 'all', 'weeks']\nğŸ”’ DATOS EXCLUIDOS: [] (letras mayÃºsculas = DATOS)\nğŸ” TOKENS PARA ANÃLISIS: ['list', 'all', 'weeks']\n   ğŸ‡ºğŸ‡¸ Conector inglÃ©s: 'all' (+10)\n   ğŸ¯ RESULTADO: INGLÃ‰S (score: 10 vs 0)\n   ğŸ‡ºğŸ‡¸ Aliases configurados para INGLÃ‰S\n   âœ… Conectores activos: 134 palabras\n   âœ… NÃºmeros activos: 43 palabras\n   âœ… Correcciones activas: 76 palabras\nğŸŒ IDIOMA DETECTADO: EN\nğŸ‡ºğŸ‡¸ CONSULTA EN INGLÃ‰S DETECTADA - ENVIANDO A PIPELINE INGLÃ‰S\nâœ… Cargado dimension_anchors.json: 19 entradas\nâœ… Cargado metric_anchors.json: 20 entradas\nğŸ”„ Mapeo reverso construido: 997 palabras mapeadas\nğŸ”— SQLSchemaMapper inicializado:\n   ğŸ“ Dimensiones: 19 anchors\n   ğŸ“Š MÃ©tricas: 20 anchors\n   ğŸ”„ Mapeos reversos: 997 palabras\nğŸ‡ºğŸ‡¸ English NLP Parser initialized with SQL Schema Mapper\n\nğŸ‡ºğŸ‡¸ PROCESSING ENGLISH QUERY: 'List all weeks'\nğŸ”§ Normalizing English query: 'list all weeks'\nâœ… English normalized: 'list all weeks'\nğŸ§ª DEBUGGING TEMPORAL DICTIONARY:\n   âŒ 'palacio de hierro' â†’ NOT FOUND\n   âŒ 'palaciodehierro' â†’ NOT FOUND\n   âŒ 'palacio_de_hierro' â†’ NOT FOUND\n   âŒ 'liverpool' â†’ NOT FOUND\nğŸ”¤ English tokens: ['list', 'all', 'weeks']\nğŸ” ANÃLISIS PRE-MAPEO de tokens originales: ['list', 'all', 'weeks']\n   ğŸ“Š PLURAL ORIGINAL detectado: 'weeks' â†’ SUM\nğŸ§  English semantic intent: SUM\nâ° DETECTING ENGLISH TEMPORAL PATTERNS:\n   ğŸ”¤ Full tokens list: ['list', 'all', 'weeks']\n   ğŸ“ Total tokens: 3\n   ğŸ” 'between' found at positions: []\nâ° TOTAL ENGLISH TEMPORAL FILTERS: 0\nğŸ¯ DETECTING ENGLISH COLUMN-VALUE PATTERNS (WITH ENHANCED STOCK OUT - ORIGINAL METHOD):\nğŸ“… DETECTING THIS WEEK PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No 'this week' pattern found\n   ğŸ”§ DEBUG: Llamando a detect_enhanced_stock_out_pattern_english...\nğŸ“¦ DETECTING ENHANCED Y/N COLUMN PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No Y/N column pattern found\n      ğŸ” Testing combination: ['list', 'all', 'weeks'] (positions 0-2)\n         ğŸ” Testing variant: 'list all weeks'\n         ğŸ” Testing variant: 'LIST ALL WEEKS'\n         ğŸ” Testing variant: 'listallweeks'\n         ğŸ” Testing variant: 'list(all(weeks'\n         ğŸ” Testing variant: 'LISTALLWEEKS'\n         ğŸ” Testing variant: 'list_all_weeks'\n         ğŸ” Testing variant: 'LIST_ALL_WEEKS'\n         ğŸ” Testing variant: 'List All Weeks'\n      ğŸ” Testing combination: ['list', 'all'] (positions 0-1)\n         ğŸ” Testing variant: 'list all'\n         ğŸ” Testing variant: 'LIST ALL'\n         ğŸ” Testing variant: 'listall'\n         ğŸ” Testing variant: 'list(all'\n         ğŸ” Testing variant: 'LISTALL'\n         ğŸ” Testing variant: 'list_all'\n         ğŸ” Testing variant: 'LIST_ALL'\n         ğŸ” Testing variant: 'List All'\n      ğŸ” Testing combination: ['list'] (positions 0-0)\n         ğŸ” Testing variant: 'list'\n         ğŸ” Testing variant: 'LIST'\n         ğŸ” Testing variant: 'List'\n      ğŸ” Testing combination: ['all', 'weeks'] (positions 1-2)\n         ğŸ” Testing variant: 'all weeks'\n         ğŸ” Testing variant: 'ALL WEEKS'\n         ğŸ” Testing variant: 'allweeks'\n         ğŸ” Testing variant: 'all(weeks'\n         ğŸ” Testing variant: 'ALLWEEKS'\n         ğŸ” Testing variant: 'all_weeks'\n         ğŸ” Testing variant: 'ALL_WEEKS'\n         ğŸ” Testing variant: 'All Weeks'\n      ğŸ” Testing combination: ['all'] (positions 1-1)\n         ğŸ” Testing variant: 'all'\n         ğŸ” Testing variant: 'ALL'\n         ğŸ” Testing variant: 'All'\n      ğŸ” Testing combination: ['weeks'] (positions 2-2)\n         ğŸ” Testing variant: 'weeks'\n         ğŸ” Testing variant: 'WEEKS'\n         ğŸ” Testing variant: 'Weeks'\nğŸ” TOTAL IMPLICIT VALUES DETECTED: 0\nğŸ”’ TOTAL POSITIONS PROCESSED: []\nâ° Temporal columns to exclude: set()\nğŸ”’ Positions already processed: []\nğŸ¯ Total filters detected: 0\n   ğŸ“¦ Enhanced stock out: 0\n   ğŸ” Implicit: 0\n   ğŸ” Explicit: 0\nğŸ”’ Final processed positions: []\nğŸ”§ REMOVING DUPLICATE FILTERS:\nğŸ¯ Final unique filters: 0\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\nğŸ• DEBUG: temporal_conditional_pattern = False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\nğŸ“‹ DEBUG: list_all_pattern = False\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\nğŸ“Š DEBUG: show_rows_pattern = False\nğŸ” CLASSIFYING ENGLISH COMPONENTS:\nğŸ” English token 'list' classified as unknown\nğŸ” English token 'all' classified as connector\nğŸ” English token 'weeks' classified as dimension\nğŸ—ï¸ BUILDING COMPLETE ENGLISH QUERY STRUCTURE\nğŸ” DETECTING GROUP BY PATTERN:\nğŸ“Š DETECTING SHOW ROWS PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… Show indicator: 'list' at position 0\n   âŒ No row count found\n   ğŸ“Š Show rows pattern detected: False\nğŸ“‹ DETECTING LIST ALL PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âœ… List indicator: 'list' at position 0\n   âœ… All indicator: 'all' at position 1\n   âŒ No target dimension found\n   ğŸ“‹ List all pattern detected: False\nğŸ• DETECTING TEMPORAL CONDITIONAL PATTERN:\n   ğŸ“¤ Tokens: ['list', 'all', 'weeks']\n   ğŸ• Temporal conditional pattern detected: False\nğŸ† DETECTING ENGLISH RANKING CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   âŒ No ranking indicators found\nğŸš« DETECTING ENGLISH EXCLUSION FILTERS:\nğŸš« TOTAL ENGLISH EXCLUSION FILTERS: 0\nğŸ† EVALUATING ENGLISH RANKING QUERY:\n   ğŸ“Š Has valid criteria: None\n   ğŸš« Exclusion filters: 0\n   ğŸ¯ Is ranking: False\n   ğŸ† Ranking detected (no special patterns): False\nğŸ”— DETECTING ENGLISH MULTIPLE DIMENSIONS:\n   ğŸ“ English dimensions found: [(2, 'weeks')]\n   ğŸ”— English connectors at positions: []\n   âŒ No valid English multi-dimensional pattern detected\nğŸ”— DETECTING ENGLISH COMPOUND CRITERIA:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\n   ğŸ“Š Segments detected: [['list', 'all', 'weeks']]\n\n   ğŸ¯ Processing English segment 1: ['list', 'all', 'weeks']\n      ğŸ” Analyzing English segment: ['list', 'all', 'weeks']\n         ğŸ“ English dimension candidate: weeks\n         ğŸ”„ English dimension converted to metric: weeks\n         âŒ English criteria incomplete:\n             Operation: NOT FOUND\n             Metric: weeks\n      âŒ Could not extract criteria from segment\n\nğŸ”— TOTAL ENGLISH COMPOUND CRITERIA: 0\nğŸ”— EVALUATING ENGLISH COMPOUND QUERY:\n   ğŸ“Š Valid criteria: 0\n   ğŸ¯ Is compound: False\n   ğŸ“ English main dimension: weeks\nğŸ” DETECTING ENGLISH QUERY PATTERN:\n   ğŸ“ Dimension: weeks\n   ğŸ”— Multiple dimensions: 1\n   âš¡ Operations: []\n   ğŸ“Š Metrics: []\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ“ Is multi-dimensional: False\n   ğŸ“‹ ENGLISH PATTERN: LIST_ALL\nğŸ† DETECTING SUPERLATIVE PATTERN:\n   ğŸ”¤ Tokens: ['list', 'all', 'weeks']\nğŸ”¢ DETECTING COUNT PATTERNS IN: 'list all weeks'\n   âŒ No COUNT pattern detected\nğŸ—ï¸ English structure built successfully:\n   ğŸ“Š Operations: 0\n   ğŸ“ˆ Metrics: 0\n   ğŸ¯ Query pattern: list_all\n   ğŸ† Is ranking: False\n   ğŸ”— Is compound: False\n   ğŸ”— Is multi-dimensional: False\n   ğŸ• Has temporal conditional: False\n   ğŸ“‹ Has list all: False\n   ğŸ“Š Has show rows: False\nğŸ”§ DEBUG: Llegando a validaciÃ³n...\nğŸ” VALIDATING ENGLISH STRUCTURE:\n   ğŸ“‹ Has list_all_pattern: False\n   ğŸ¯ Validation result: {'valid': False, 'error': 'Missing metric, operation or condition', 'suggestions': ['Add a metric like: sales, revenue, inventory', 'English unrecognized words: list']}\nğŸ”§ DEBUG: ValidaciÃ³n result = {'valid': False, 'error': 'Missing metric, operation or condition', 'suggestions': ['Add a metric like: sales, revenue, inventory', 'English unrecognized words: list']}",
      "stderr_content": "",
      "has_content": true
    }
  }
]